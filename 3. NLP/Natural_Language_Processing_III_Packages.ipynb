{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Other NLP Packages: spaCy, Gensim, and Textacy</center>\n",
    "\n",
    "References: \n",
    "- https://nlpforhackers.io/complete-guide-to-spacy/\n",
    "- https://radimrehurek.com/gensim/models/phrases.html\n",
    "- https://stanfordnlp.github.io/stanza/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. spaCy\n",
    "- spaCy is a relatively new framework in the Python Natural Language Processing, but is getting popular\n",
    "- Provides models for Part Of Speech tagging, Named Entity Recognition and Dependency Parsing\n",
    "<img src='https://spacy.io/images/pipeline.svg' width = \"60%\">\n",
    "- Supports 8 languages out of the box\n",
    "- Provides easy and beautiful visualizations\n",
    "- PProvides pretrained word vectors\n",
    "- installation:\n",
    "  1. `pip install spacy`\n",
    "  2. `python -m spacy download en` or `python -m spacy download en_core_web_sm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: setuptools in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.10.6)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: jinja2 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy) (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1106444910.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/16/sj7htwpn37x5chbjt67h8nrr0000gn/T/ipykernel_17822/1106444910.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install spacy\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Installation\n",
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.1. Load package and language library\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# if you downloaded en_core_web_sm use the following:\n",
    "#import en_core_web_sm \n",
    "#nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/16/sj7htwpn37x5chbjt67h8nrr0000gn/T/ipykernel_18067/359203801.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Exercise 1.2. Get POS, lemmatization, and other NLP tasks all in one task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Next week I'll be in Madrid.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"text\\tlemma\\tpunct?\\tspace?\\tstopword?\\tpos\\ttag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Exercise 1.2. Get POS, lemmatization, and other NLP tasks all in one task\n",
    "\n",
    "doc = nlp(\"Next week I'll be in Madrid.\")\n",
    "print(f\"text\\tlemma\\tpunct?\\tspace?\\tstopword?\\tpos\\ttag\")\n",
    "for token in doc:\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t\\t{5}\\t{6}\".format(\n",
    "        token.text,         # original text\n",
    "        token.lemma_,       # lemma\n",
    "        token.is_punct,     # is it a punctuation ?\n",
    "        token.is_space,     # is it a space\n",
    "        token.is_stop,\n",
    "        token.pos_,         # The simple part-of-speech tag.\n",
    "        token.tag_          # The detailed part-of-speech tag\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment documents in sentences. Note here spacy has a hierarchical structure:\n",
    "- Top: nlp object\n",
    "- Level 1: Sentences\n",
    "- Level 2: Tokens of each sentence\n",
    "- Level 3: A token has a variety of properties, e.g., tag, pos, is_punct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 These are apples.\n",
      "text\tlemma\tpunct?\tspace?\tstopword?\tpos\ttag\n",
      "These\tthese\tFalse\tFalse\tTrue\t\tPRON\tDT\n",
      "are\tbe\tFalse\tFalse\tTrue\t\tAUX\tVBP\n",
      "apples\tapple\tFalse\tFalse\tFalse\t\tNOUN\tNNS\n",
      ".\t.\tTrue\tFalse\tFalse\t\tPUNCT\t.\n",
      "\n",
      "\n",
      "1 These are oranges.\n",
      "text\tlemma\tpunct?\tspace?\tstopword?\tpos\ttag\n",
      "These\tthese\tFalse\tFalse\tTrue\t\tPRON\tDT\n",
      "are\tbe\tFalse\tFalse\tTrue\t\tAUX\tVBP\n",
      "oranges\torange\tFalse\tFalse\tFalse\t\tNOUN\tNNS\n",
      ".\t.\tTrue\tFalse\tFalse\t\tPUNCT\t.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.3. Segment by sentences. \n",
    "# Note doc.sents contains all sentence objects\n",
    "\n",
    "doc = nlp(\"These are apples. These are oranges.\")\n",
    " \n",
    "for i, sent in enumerate(doc.sents):\n",
    "    print(i, sent)\n",
    "    print(f\"text\\tlemma\\tpunct?\\tspace?\\tstopword?\\tpos\\ttag\")\n",
    "    for token in sent:\n",
    "        print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t\\t{5}\\t{6}\".format(\n",
    "        token.text,         # original text\n",
    "        token.lemma_,       # lemma\n",
    "        token.is_punct,     # is it a punctuation ?\n",
    "        token.is_space,     # is it a space\n",
    "        token.is_stop,\n",
    "        token.pos_,         # The simple part-of-speech tag.\n",
    "        token.tag_          # The detailed part-of-speech tag\n",
    "    ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t\t CARDINAL\n",
      "9 a.m. \t\t TIME\n",
      "30% \t\t PERCENT\n",
      "just 2 days \t\t DATE\n",
      "WSJ \t\t ORG\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.4. Entity Recognition\n",
    "\n",
    "doc = nlp(\"I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ'\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"\\t\\t\", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I just bought \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " shares at \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    9 a.m.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " because the stock went up \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    30%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    just 2 days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " according to the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WSJ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 1.5. Visulaize named entities\n",
    "\n",
    "from spacy import displacy\n",
    " \n",
    "doc = nlp('I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ')\n",
    "print(doc)\n",
    "displacy.render(doc, style='ent', jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"7114eda47a494202ad49f93dd51230e8-0\" class=\"displacy\" width=\"2030\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">just</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">bought</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">2</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">shares</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">9</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">a.m.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">because</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">stock</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">went</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">up</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1220\">30%</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1220\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1310\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1310\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">just</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">2</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1580\">days</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1580\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1670\">according</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1670\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1760\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1760\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1940\">WSJ</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1940\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,92.0 220.0,92.0 220.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-1\" stroke-width=\"2px\" d=\"M160,182.0 C160,137.0 215.0,137.0 215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,184.0 L152,172.0 168,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-2\" stroke-width=\"2px\" d=\"M340,182.0 C340,137.0 395.0,137.0 395.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,184.0 L332,172.0 348,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-3\" stroke-width=\"2px\" d=\"M250,182.0 C250,92.0 400.0,92.0 400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,184.0 L408.0,172.0 392.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-4\" stroke-width=\"2px\" d=\"M250,182.0 C250,47.0 495.0,47.0 495.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M495.0,184.0 L503.0,172.0 487.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-5\" stroke-width=\"2px\" d=\"M610,182.0 C610,137.0 665.0,137.0 665.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,184.0 L602,172.0 618,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-6\" stroke-width=\"2px\" d=\"M520,182.0 C520,92.0 670.0,92.0 670.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670.0,184.0 L678.0,172.0 662.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-7\" stroke-width=\"2px\" d=\"M790,182.0 C790,92.0 1030.0,92.0 1030.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,184.0 L782,172.0 798,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-8\" stroke-width=\"2px\" d=\"M880,182.0 C880,137.0 935.0,137.0 935.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-9\" stroke-width=\"2px\" d=\"M970,182.0 C970,137.0 1025.0,137.0 1025.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M970,184.0 L962,172.0 978,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-10\" stroke-width=\"2px\" d=\"M250,182.0 C250,2.0 1040.0,2.0 1040.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1040.0,184.0 L1048.0,172.0 1032.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-11\" stroke-width=\"2px\" d=\"M1060,182.0 C1060,137.0 1115.0,137.0 1115.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1115.0,184.0 L1123.0,172.0 1107.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-12\" stroke-width=\"2px\" d=\"M1150,182.0 C1150,137.0 1205.0,137.0 1205.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1205.0,184.0 L1213.0,172.0 1197.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-13\" stroke-width=\"2px\" d=\"M1060,182.0 C1060,92.0 1300.0,92.0 1300.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1300.0,184.0 L1308.0,172.0 1292.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-14\" stroke-width=\"2px\" d=\"M1420,182.0 C1420,137.0 1475.0,137.0 1475.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1420,184.0 L1412,172.0 1428,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-15\" stroke-width=\"2px\" d=\"M1510,182.0 C1510,137.0 1565.0,137.0 1565.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1510,184.0 L1502,172.0 1518,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-16\" stroke-width=\"2px\" d=\"M1330,182.0 C1330,92.0 1570.0,92.0 1570.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1570.0,184.0 L1578.0,172.0 1562.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-17\" stroke-width=\"2px\" d=\"M1060,182.0 C1060,47.0 1665.0,47.0 1665.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1665.0,184.0 L1673.0,172.0 1657.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-18\" stroke-width=\"2px\" d=\"M1690,182.0 C1690,137.0 1745.0,137.0 1745.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1745.0,184.0 L1753.0,172.0 1737.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-19\" stroke-width=\"2px\" d=\"M1870,182.0 C1870,137.0 1925.0,137.0 1925.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1870,184.0 L1862,172.0 1878,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7114eda47a494202ad49f93dd51230e8-0-20\" stroke-width=\"2px\" d=\"M1780,182.0 C1780,92.0 1930.0,92.0 1930.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7114eda47a494202ad49f93dd51230e8-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1930.0,184.0 L1938.0,172.0 1922.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 1.6. Visualized dependency graph\n",
    "\n",
    "from spacy import displacy\n",
    " \n",
    "doc = nlp(\"I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ\")\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Textacy\n",
    "\n",
    "Textacy is a Python library for performing a variety of (NLP) tasks, built on the high-performance spaCy library. With the fundamentals — tokenization, part-of-speech tagging, dependency parsing, etc. \n",
    "\n",
    "For details, check https://textacy.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation.\n",
    "#! pip install textacy\n",
    "\n",
    "\n",
    "from textacy import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "     \"Since the so-called \\\"statistical revolution\\\" in the late 1980s and mid 1990s, \"\n",
    "     \"much Natural Language Processing research has relied heavily on machine learning. \"\n",
    "     \"Formerly, many language-processing tasks typically involved the direct hand coding \"\n",
    "     \"of rules, which is not in general robust to natural language variation. \"\n",
    "     \"The machine-learning paradigm calls instead for using statistical inference \"\n",
    "     \"to automatically learn such rules through the analysis of large corpora \"\n",
    "     \"of typical real-world examples.\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the so called  statistical revolution  in the late 1980s and mid 1990s  much Natural Language Processing research has relied heavily on machine learning  Formerly  many language processing tasks typically involved the direct hand coding of rules  which is not in general robust to natural language variation  The machine learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora of typical real world examples \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Since the so called statistical revolution in the late 1980s and mid 1990s much Natural Language Processing research has relied heavily on machine learning Formerly many language processing tasks typically involved the direct hand coding of rules which is not in general robust to natural language variation The machine learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora of typical real world examples'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuation\n",
    "\n",
    "from textacy import preprocessing\n",
    "\n",
    "text_remove_punct = preprocessing.remove.punctuation(text)\n",
    "print(text_remove_punct)\n",
    "\n",
    "# remove whitespace\n",
    "preprocessing.normalize.whitespace(text_remove_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make spacy doc\n",
    "import textacy\n",
    "\n",
    "# load English language model\n",
    "en = textacy.load_spacy_lang(\"en_core_web_sm\")\n",
    "\n",
    "doc = textacy.make_spacy_doc(text, lang=en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[statistical revolution,\n",
       " late 1980s,\n",
       " mid 1990s,\n",
       " Natural Language,\n",
       " Language Processing,\n",
       " Processing research,\n",
       " relied heavily,\n",
       " machine learning,\n",
       " processing tasks,\n",
       " tasks typically,\n",
       " typically involved,\n",
       " direct hand,\n",
       " hand coding,\n",
       " general robust,\n",
       " natural language,\n",
       " language variation,\n",
       " learning paradigm,\n",
       " paradigm calls,\n",
       " calls instead,\n",
       " statistical inference,\n",
       " automatically learn,\n",
       " large corpora,\n",
       " typical real,\n",
       " world examples,\n",
       " 1980s and mid,\n",
       " Natural Language Processing,\n",
       " Language Processing research,\n",
       " research has relied,\n",
       " heavily on machine,\n",
       " processing tasks typically,\n",
       " tasks typically involved,\n",
       " involved the direct,\n",
       " direct hand coding,\n",
       " coding of rules,\n",
       " robust to natural,\n",
       " natural language variation,\n",
       " learning paradigm calls,\n",
       " paradigm calls instead,\n",
       " inference to automatically,\n",
       " learn such rules,\n",
       " analysis of large,\n",
       " corpora of typical]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract bigrams and trigrams\n",
    "list(textacy.extract.ngrams(doc, n = (2,3), filter_stops=True, \\\n",
    "                            filter_punct=True, filter_nums=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural Language Processing research', 0.05801429969492685),\n",
       " ('natural language variation', 0.047242782528362955),\n",
       " ('direct hand coding', 0.03817002256131215),\n",
       " ('statistical inference', 0.03359364905765383),\n",
       " ('machine learning', 0.03326750227139413),\n",
       " ('statistical revolution', 0.030629349149736886),\n",
       " ('late 1980', 0.026186881678224555),\n",
       " ('general robust', 0.025591268483622656),\n",
       " ('processing task', 0.025420643340329566),\n",
       " ('typical real', 0.025416316515447297)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract key terms\n",
    "\n",
    "from textacy.extract import keyterms as kt\n",
    "kt.textrank(doc, normalize=\"lemma\", \n",
    "            include_pos =('NOUN', 'PROPN', 'ADJ'),\n",
    "            window_size = 3,\n",
    "            topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural Language Processing research', 0.059959246697826624),\n",
       " ('natural language variation', 0.04488350959275309),\n",
       " ('direct hand coding', 0.037736661821063354),\n",
       " ('statistical inference', 0.03432557996664981),\n",
       " ('statistical revolution', 0.034007535820683756),\n",
       " ('machine learning', 0.03305919655573349),\n",
       " ('late 1980', 0.026499549123496648),\n",
       " ('processing task', 0.0256684200517989),\n",
       " ('general robust', 0.024835834233545625),\n",
       " ('typical real', 0.02381966456140927)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract key terms \n",
    "\n",
    "# If you get an error related to NetworkX, downgrade networkX version to 2.5\n",
    "\n",
    "from textacy.extract import keyterms as kt\n",
    "kt.textrank(doc, normalize=\"lemma\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. gensim\n",
    "- Gensim is an open source Python library for NLP, with a focus on topic modeling.\n",
    "- It is not an everything-including-the-kitchen-sink NLP research library (like NLTK); instead, Gensim is a mature, focused, and efficient suite of NLP tools for topic modeling, including \n",
    "  - Word2Vec word embedding \n",
    "  - Topic modeling\n",
    "  - Text preprocessing like **phrase extraction**\n",
    "  \n",
    "- Gensim Phrase Model: \n",
    "    - `gensim.models.phrases.Phrases(sentences, min_count, threshold, max_vocab_size, delimiter, scoring, ...)`\n",
    "        - `sentences`: list of sentences or iterables, each of which can be a document\n",
    "        - `min_count`: Ignore all words and bigrams with total collected count lower than this value.\n",
    "        - `threshold`: Represent a score threshold for forming the phrases (higher means fewer phrases). A phrase of words $a$ followed by $b$ is accepted if the score of the phrase is greater than threshold. Heavily depends on concrete scoring-function.\n",
    "        - `max_vocab_size`: Maximum size (number of tokens) of the vocabulary. \n",
    "        - `delimiter`: Glue character used to join collocation tokens, should be a byte string (e.g. '\\_').\n",
    "        - `scoring`: Specify how potential phrases are scored. \n",
    "           - `default` - original_scorer(), by Mikolov et al. (2013) (https://arxiv.org/pdf/1310.4546.pdf)\n",
    "           - `npmi` - npmi_scorer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santo_Domingo:\t8549.11\n",
      "specie_payments:\t6411.83\n",
      "Indian_tribes:\t6411.83\n",
      "Social_Security:\t6411.83\n",
      "Founding_Fathers:\t6411.83\n",
      "Abraham_Lincoln:\t6411.83\n",
      "illegal_liquor:\t5129.47\n",
      "merchant_marine:\t4808.88\n",
      "Western_Hemisphere:\t4808.88\n",
      "Supreme_Court:\t4274.56\n",
      "founding_documents:\t4274.56\n",
      "lock_type:\t3847.10\n",
      "Old_World:\t3108.77\n",
      "inland_frontiers:\t2747.93\n",
      "¡_Xand:\t2564.73\n",
      "coordinate_branches:\t2355.37\n",
      "Thomas_Jefferson:\t2331.58\n",
      "eighteenth_amendment:\t2137.28\n",
      "Chief_Magistrate:\t1998.49\n",
      "extra_session:\t1972.87\n",
      "Great_Britain:\t1923.55\n",
      "George_Washington:\t1846.61\n",
      "silent_prayer:\t1810.40\n",
      "faithfully_executed:\t1803.33\n",
      "entangling_alliances:\t1748.68\n",
      "fervent_supplications:\t1709.82\n",
      "nuclear_weapons:\t1648.76\n",
      "distinguished_guests:\t1538.84\n",
      "Civil_War:\t1465.56\n",
      "onward_march:\t1424.85\n",
      "Chief_Justice:\t1373.96\n",
      "plainly_written:\t1373.96\n",
      "middle_class:\t1221.30\n",
      "fifteenth_amendment:\t1068.64\n",
      "earliest_practicable:\t961.78\n",
      "preceding_term:\t961.78\n",
      "fertile_soil:\t961.78\n",
      "walk_humbly:\t874.34\n",
      "World_War:\t814.20\n",
      "tariff_bill:\t744.60\n",
      "regular_session:\t739.83\n",
      "Vice_President:\t682.03\n",
      "executive_department:\t646.57\n",
      "standing_armies:\t635.88\n",
      "technical_knowledge:\t625.54\n",
      "hard_choices:\t610.65\n",
      "Divine_Providence:\t601.11\n",
      "move_forward:\t601.11\n",
      "President_Bush:\t539.94\n",
      "entirely_consistent:\t538.06\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2.1. Find bigrams using gensim\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "\n",
    "words=nltk.corpus.inaugural.words()\n",
    "\n",
    "# Train phrase model to find phrases using original_scorer\n",
    "phrases = Phrases([words], min_count=2, threshold=50)\n",
    "\n",
    "# get unique set of phrases and sorted by score in descending order\n",
    "items = sorted(set(phrases.find_phrases([words]).items()), key=lambda item: -item[1])\n",
    "\n",
    "# print top 50 phrases\n",
    "for phrase, score in items[0:50]:\n",
    "    print(\"{0}:\\t{1:.2f}\".format(phrase, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porto_Rico:\t1.00\n",
      "Panama_Canal:\t1.00\n",
      "reverend_clergy:\t1.00\n",
      "Information_Age:\t1.00\n",
      "Santo_Domingo:\t1.00\n",
      "Rocky_Mountains:\t1.00\n",
      "Philippine_Islands:\t1.00\n",
      "Social_Security:\t0.97\n",
      "Founding_Fathers:\t0.97\n",
      "Indian_tribes:\t0.97\n",
      "'_s:\t0.96\n",
      "specie_payments:\t0.96\n",
      "Abraham_Lincoln:\t0.96\n",
      "illegal_liquor:\t0.95\n",
      "merchant_marine:\t0.95\n",
      "Majority_Leader:\t0.94\n",
      "electors_residing:\t0.94\n",
      "Western_Hemisphere:\t0.94\n",
      "founding_documents:\t0.94\n",
      "Old_World:\t0.93\n",
      "sheet_anchor:\t0.93\n",
      "lock_type:\t0.93\n",
      "Supreme_Court:\t0.92\n",
      "cleaner_environment:\t0.92\n",
      "Middle_East:\t0.92\n",
      "secondary_boycott:\t0.92\n",
      "Dingley_Act:\t0.92\n",
      "start_afresh:\t0.92\n",
      "elective_franchise:\t0.90\n",
      "Permanent_Court:\t0.90\n",
      "inland_frontiers:\t0.90\n",
      "Chief_Magistrate:\t0.88\n",
      "United_States:\t0.88\n",
      "200th_anniversary:\t0.88\n",
      "Thomas_Jefferson:\t0.88\n",
      "¡_Xand:\t0.88\n",
      "coordinate_branches:\t0.87\n",
      "Chief_Justice:\t0.87\n",
      "Pacific_Coast:\t0.87\n",
      "exclusive_metallic:\t0.87\n",
      "extra_session:\t0.86\n",
      "eighteenth_amendment:\t0.86\n",
      "Senator_Dole:\t0.86\n",
      "Senator_Mathias:\t0.86\n",
      "temporary_restraining:\t0.86\n",
      "entangling_alliances:\t0.85\n",
      "fugitive_slaves:\t0.85\n",
      "fervent_supplications:\t0.85\n",
      "Great_Britain:\t0.85\n",
      "George_Washington:\t0.84\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2.2. Find bigrams by NPMI\n",
    "\n",
    "# find phrases using NPMI\n",
    "\n",
    "phrases = Phrases([words], min_count=2, threshold=0.5, \\\n",
    "                  scoring='npmi')\n",
    "\n",
    "# get unique set of phrases and sorted by score in descending order\n",
    "items = sorted(set(phrases.find_phrases([words]).items()), key=lambda item: -item[1])\n",
    "\n",
    "# print top 20 phrases\n",
    "for phrase, score in items[0:50]:\n",
    "    print(\"{0}:\\t{1:.2f}\".format(phrase, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That we are in the midst of crisis is now well understood. Our nation is at war, against a far-reaching network of violence and hatred. Our economy is badly weakened, a consequence of greed and irresponsibility on the part of some, but also our collective failure to make hard choices and prepare the nation for a new age. Homes have been lost; jobs shed; businesses shuttered. Our health care is too costly; our schools fail too many; and each day brings further evidence that the ways we use energy strengthen our adversaries and threaten our planet.\n",
      "['That', 'we', 'are', 'in', 'the', 'midst', 'of', 'crisis', 'is', 'now', 'well', 'understood.', 'Our', 'nation', 'is', 'at', 'war,', 'against', 'a', 'far-reaching', 'network', 'of', 'violence', 'and', 'hatred.', 'Our', 'economy', 'is', 'badly', 'weakened,', 'a', 'consequence', 'of', 'greed', 'and', 'irresponsibility', 'on', 'the', 'part', 'of', 'some,', 'but', 'also', 'our', 'collective', 'failure', 'to', 'make', 'hard_choices', 'and', 'prepare', 'the', 'nation', 'for', 'a', 'new', 'age.', 'Homes', 'have_been', 'lost;', 'jobs', 'shed;', 'businesses', 'shuttered.', 'Our', 'health_care', 'is', 'too', 'costly;', 'our', 'schools', 'fail', 'too', 'many;', 'and', 'each', 'day', 'brings', 'further', 'evidence', 'that', 'the', 'ways', 'we', 'use', 'energy', 'strengthen', 'our', 'adversaries', 'and', 'threaten', 'our', 'planet.']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2.3. Tokenize by unigrams and bigrams\n",
    "\n",
    "# Initialize phrase tokenizer\n",
    "bigram = Phraser(phrases)\n",
    "\n",
    "\n",
    "#sent = nltk.corpus.inaugural.raw('2009-Obama.txt')\n",
    "\n",
    "sent = '''That we are in the midst of crisis is now well understood. Our nation is at war, against a far-reaching network of violence and hatred. Our economy is badly weakened, a consequence of greed and irresponsibility on the part of some, but also our collective failure to make hard choices and prepare the nation for a new age. Homes have been lost; jobs shed; businesses shuttered. Our health care is too costly; our schools fail too many; and each day brings further evidence that the ways we use energy strengthen our adversaries and threaten our planet.'''\n",
    "\n",
    "print(sent)\n",
    "\n",
    "print(bigram[sent.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
