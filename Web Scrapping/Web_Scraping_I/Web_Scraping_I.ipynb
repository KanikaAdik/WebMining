{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Web Scraping</center>\n",
    "\n",
    "References: \n",
    " - https://www.dataquest.io/blog/web-scraping-tutorial-python/\n",
    " - https://www.crummy.com/software/BeautifulSoup/bs4/doc/#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Different ways to access data on the web\n",
    " - Scrape HTML web pages \n",
    " - Download data file directly \n",
    "    * data files such as csv, txt\n",
    "    * pdf files\n",
    " - Access data through Application Programming Interface (API), e.g. The Movie DB, Twitter\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Basic structure of HTML ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HTML tags: <font color=\"green\">head</font>, <font color=\"green\">body</font>, <font color=\"green\">p</font>, <font color=\"green\">a</font>, <font color=\"green\">form</font>, <font color=\"green\">table </font>, ...\n",
    "* A tag may have properties. \n",
    "  * For example, tag <font color=\"green\">a</font> has property (or attribute) <font color=\"green\">href</font>, the target of the link\n",
    "  *  <font color=\"green\">class</font> and <font color=\"green\">id</font> are special properties used by html to control the style of each element through Cascading Style Sheets (CSS). <font color=\"green\">id</font> is the unique identifier of an element, and <font color=\"green\">class</font> is used to group elements for styling. \n",
    "      - An element can be associated with multiple classes. These classes are separated by space, e.g. `<h2 class=\"city main\">London</h2>`\n",
    "      - Very often, we can scrape by class (e.g. all `city` names) if CSS is used in the page\n",
    "      - For an illustrative example, check https://www.w3schools.com/html/tryit.asp?filename=tryhtml_classes_multiple\n",
    "* A tag can be referenced by its position in relation to each other \n",
    "  * **child** – a child is a tag inside another tag, e.g. the two <font color=\"green\">p</font> tags are children of the <font color=\"green\">div</font> tag.\n",
    "  * **parent** – a parent is the tag another tag is inside, e.g. the <font color=\"green\">html</font> tag is the parent of the <font color=\"green\">body</font> tag.\n",
    "  * **sibling** – a sibling is a tag that has the same parent as another tag, e.g. in the html example, the <font color=\"green\">head</font> and <font color=\"green\">body</font> tags are siblings, since they’re both inside <font color=\"green\">html</font>. Both <font color=\"green\">p</font> tags are siblings, since they’re both inside <font color=\"green\">body</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample html source code (http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html).\n",
    "* A html document can be viewed as a tree structure\n",
    "\n",
    "<img src=\"html.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web page displayed:\n",
    "--------------------\n",
    "\n",
    "First paragraph.\n",
    "\n",
    "Second paragraph.\n",
    "\n",
    "**First outer paragraph.**\n",
    "\n",
    "**Second outer paragraph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Access HTML Elements: CSS Selector and XPATH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. CSS Selector \n",
    "- Most HTML pages are styled using CSS. \n",
    "- Identifying the various elements (e.g. `<h2 class=\"city main\">London</h2>`) on a page based on styles requires you to select the class (e.g. `city`) it falls into. \n",
    "- A CSS selector allows you to pick out the elements associated with CSS styles. \n",
    "- Advantages of Using CSS Selector\n",
    "  * It’s faster than XPath.\n",
    "  * It’s much easier to learn and implement.\n",
    "  * You have a high chance of finding your elements, since most CSS elements have explicit names or categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. XPath \n",
    "- XPath stands for XML Path -- a query language that helps identify elements from an XML document (HTML can be considered as XML too)\n",
    "- It uses expressions that navigate into an XML document in a way that can be traced from the start to the intended element—like forming a path from the start, e.g.\n",
    "  - `/`: root of the document\n",
    "  - `//`: start from anywhere of the document\n",
    "  - `@`: attribute\n",
    "  - `/html//p`: retrieve all `p` tags under `html` from the root\n",
    "  - `//p[@id=\"first\"]`: retrieve all `p` tags with an attribute `id` with value `first`\n",
    "  \n",
    "- Advantage:\n",
    "   - Flexible\n",
    "   - Support pattern match in element selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Examples of CSS Selector and XPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Goal|CSS Selector|XPath| \n",
    "|:-----|:-----|:-----|\n",
    "|All `P` elements|`p`|`//p` |  \n",
    "|All `p` descendants  under `body` | `body p`| `//body//p`|  \n",
    "|Element (e.g. `p`) By ID (e.g. `first`) |`p#first`|`//p[@id=’first’] ` |    \n",
    "|Element (e.g. `p`) By Class (e.g. `inner-text`)|`p.inner-text`|`//p[contains(@class,’inner-text’)]`|\n",
    "|Element (e.g. `p`) with Attribute (e.g. `name`)|`p[name=xyz]`|`//p[@name='xyz']`|    \n",
    "|All child elements under `p`|`p>*`|`//p/*`|          \n",
    "|First child of all P|`p>*:first-child`|`//p/*[0]`|                     \n",
    "|All P with an `a` child|Not possible|`//p[a]` |                      \n",
    "|Next element|`p + *`|`//p/following-sibling::*[0]`|\n",
    "|Previous element|Not possible|`//p/preceding-sibling::*[0]`|\n",
    "\n",
    "- For details of XPath, see https://www.w3schools.com/xml/xpath_syntax.asp\n",
    "- For details of CSS Selector, see https://www.w3schools.com/cssref/css_selectors.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Steps to scape HTML web pages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. Preparation\n",
    "     * Install modules <font color=\"green\">requests</font>, <font color=\"green\">BeautifulSoup4/scrapy/selenium/...</font>.\n",
    "        * **requests**: allow you to send HTTP/1.1 requests using Python. To install:\n",
    "           - Open terminal (Mac) or Anaconda Command Prompt (Windows)\n",
    "           - Issue: `pip install requests`\n",
    "        * **BeautifulSoup**: web page parsing library, to install, use: `pip install beautifulsoup4`\n",
    "     \n",
    "  2. Use <font color=\"green\">**requests**</font> library to retrive the source code\n",
    "  3. View **source code of the web page**: find out html elements that you will scrape\n",
    "      * **Firefox**: right click on the web page and select \"view page source\"\n",
    "      * **Safari**: Select the Develop menu in the top menu bar. Select the Show Page Source option to open a text window with the HTML source of the page\n",
    "      * **Chrome**: Navigate to “View,” click on “Developer,” and then “View Source,” or right-click and select “View Page Source.” \n",
    "  4. Use libraries to parse the source code. Available libraries:\n",
    "      * <font color=\"green\">Beautifulsoup</font>: Simple, support CSS Selector, but not XPath\n",
    "      * <font color=\"green\">scrapy (https://scrapy.org/)</font>: Support CSS Selector and  XPath\n",
    "      * <font color=\"green\">Selenium</font>: Can scrape dynamic web pages\n",
    "      * <font color=\"green\">lxml</font>: another good library for web page scraping\n",
    "      * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scrape the sample html using BeautifulSoup ###\n",
    "- Kinds of Objects in BeautifulSoup\n",
    "  * <font color=\"green\">**Tag**</font>: an xml or HTML tag\n",
    "  * <font color=\"green\">**Name**</font>: every tag has a name\n",
    "  * <font color=\"green\">**Attributes**</font>: a tag may have any number of attributes. A tag is shown as a **dictionary** in the form of {attribute1_name:attribute1_value, attribute2_name:attribute2_value, ...}. If an attribute has multiple values, the value is stored as a list\n",
    "  * <font color=\"green\">**NavigableString**</font>: the text within a tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Retrieve HTML and Navigate the HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.1.1 Import requests and beautifulsoup packages\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# import requests package\n",
    "import requests                   \n",
    "\n",
    "# import BeautifulSoup from package bs4 (i.e. beautifulsoup4)\n",
    "from bs4 import BeautifulSoup     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <div>\\n            <p class=\"inner-text first-item\" id=\"first\">\\n                First paragraph.\\n            </p>\\n            <p class=\"inner-text\">\\n                Second paragraph.\\n            </p>\\n        </div>\\n        <p class=\"outer-text first-item\" id=\"second\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>\\n        <p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>\\n    </body>\\n</html>'\n",
      "<html>\n",
      "    <head>\n",
      "        <title>A simple example page</title>\n",
      "    </head>\n",
      "    <body>\n",
      "        <div>\n",
      "            <p class=\"inner-text first-item\" id=\"first\">\n",
      "                First paragraph.\n",
      "            </p>\n",
      "            <p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>\n",
      "        </div>\n",
      "        <p class=\"outer-text first-item\" id=\"second\">\n",
      "            <b>\n",
      "                First outer paragraph.\n",
      "            </b>\n",
      "        </p>\n",
      "        <p class=\"outer-text\">\n",
      "            <b>\n",
      "                Second outer paragraph.\n",
      "            </b>\n",
      "        </p>\n",
      "    </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.2 Get web page content\n",
    "\n",
    "# send a get request to the web page\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")    \n",
    "\n",
    "# status_code 200 indicates success. \n",
    "# a status code >200 indicates a failure\n",
    "if page.status_code==200:   \n",
    "    \n",
    "    # content property gives the content returned in bytes \n",
    "    print(page.content)  # text in bytes\n",
    "    print(page.text)     # text in unicode\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3 string class (str) stores Unicode strings \n",
    "#and a new byte string (bytes) class supports single byte strings. The two are different types so string expressions must use one form or the other. String literals are Unicode unless prefixed with a lower case `b`.\n",
    "\n",
    "To convert byte strings to Unicode use the bytes.decode() method and use str.encode() to covert a byte string to a unicode string.\n",
    "\n",
    "For details, see https://blog.feabhas.com/2019/02/python-3-unicode-and-byte-strings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basics of HTTP (Hypertext Transfer Protocol)**\n",
    "- HTTP is designed to enable communications between clients (e.g. browser) and servers (e.g. Apache web server).\n",
    "- A client submits an HTTP **request** to the server; then the server returns a **response** to the client. \n",
    "- Two commonly used methods for a request-response between a client and server:\n",
    "  - GET - Requests data from a specified resource\n",
    "  - POST - Submits data to be processed to a specified resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soup object:\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <p class=\"inner-text first-item\" id=\"first\">\n",
      "    First paragraph.\n",
      "   </p>\n",
      "   <p class=\"inner-text\">\n",
      "    Second paragraph.\n",
      "   </p>\n",
      "  </div>\n",
      "  <p class=\"outer-text first-item\" id=\"second\">\n",
      "   <b>\n",
      "    First outer paragraph.\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"outer-text\">\n",
      "   <b>\n",
      "    Second outer paragraph.\n",
      "   </b>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.3 Parse web page content\n",
    "\n",
    "# Process the returned content using beautifulsoup module\n",
    "\n",
    "# initiate a beautifulsoup object using the html source and Python’s html.parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')  \n",
    "\n",
    "# soup object stands for the **root** \n",
    "# node of the html document tree\n",
    "\n",
    "print(\"Soup object:\")\n",
    "\n",
    "\n",
    "# print soup object nicely\n",
    "print(soup.prettify())                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "soup children nodes:\n",
      "<list_iterator object at 0x7fed6843d520>\n",
      "\n",
      "list of children of root:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# soup.children returns an iterator of all children nodes\n",
    "print(\"\\nsoup children nodes:\")\n",
    "soup_children=soup.children\n",
    "print(soup_children)\n",
    "\n",
    "# convert to list\n",
    "soup_children=list(soup.children)\n",
    "print(\"\\nlist of children of root:\")\n",
    "print(len(soup_children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                    \n",
    "# html is the only child of the root node\n",
    "html=soup_children[0]    \n",
    "\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many children under html?  5\n",
      "Child 0 is: \n",
      "\n",
      "\n",
      "Child 1 is: <head>\n",
      "<title>A simple example page</title>\n",
      "</head>\n",
      "\n",
      "Child 2 is: \n",
      "\n",
      "\n",
      "Child 3 is: <body>\n",
      "<div>\n",
      "<p class=\"inner-text first-item\" id=\"first\">\n",
      "                First paragraph.\n",
      "            </p>\n",
      "<p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>\n",
      "</div>\n",
      "<p class=\"outer-text first-item\" id=\"second\">\n",
      "<b>\n",
      "                First outer paragraph.\n",
      "            </b>\n",
      "</p>\n",
      "<p class=\"outer-text\">\n",
      "<b>\n",
      "                Second outer paragraph.\n",
      "            </b>\n",
      "</p>\n",
      "</body>\n",
      "\n",
      "Child 4 is: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.4 Get head and body tag\n",
    "\n",
    "html_children=list(html.children)\n",
    "\n",
    "print(\"how many children under html? \", len(html_children))\n",
    "\n",
    "for idx, child in enumerate(html_children):\n",
    "    print(\"Child {} is: {}\\n\".format(idx, child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "head text:\n",
      "\n",
      "A simple example page\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                First paragraph.\n",
      "            \n",
      "\n",
      "                Second paragraph.\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "                First outer paragraph.\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "                Second outer paragraph.\n",
      "            \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# head is the second child of html\n",
    "head=html_children[1]\n",
    "\n",
    "# extract all text inside head\n",
    "print(\"\\nhead text:\")\n",
    "print(head.get_text())\n",
    "\n",
    "# body is the fourth child of html\n",
    "body=html_children[3]\n",
    "print(body.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<div>\n",
      "<p class=\"inner-text first-item\" id=\"first\">\n",
      "                First paragraph.\n",
      "            </p>\n",
      "<p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>\n",
      "</div>\n",
      "<p class=\"outer-text first-item\" id=\"second\">\n",
      "<b>\n",
      "                First outer paragraph.\n",
      "            </b>\n",
      "</p>\n",
      "<p class=\"outer-text\">\n",
      "<b>\n",
      "                Second outer paragraph.\n",
      "            </b>\n",
      "</p>\n",
      "</body>\n",
      "div <div>\n",
      "<p class=\"inner-text first-item\" id=\"first\">\n",
      "                First paragraph.\n",
      "            </p>\n",
      "<p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>\n",
      "</div>\n",
      "OLD Div\n",
      "first p : <p class=\"inner-text first-item\" id=\"first\">\n",
      "                First paragraph.\n",
      "            </p>\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.5 Continue the navigation through html document tree \n",
    "\n",
    "# Task 1. get div tag inside body. \n",
    "# div is the second child of body\n",
    "print(body)\n",
    "\n",
    "print(\"div\", body.div)\n",
    "print(\"OLD Div\", )\n",
    "\n",
    "# Task 2: get the first p in div (2nd child of div)\n",
    "print(\"first p :\", body.div.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data type:\n",
      "<class 'bs4.element.Tag'>\n",
      "\n",
      "tag name: \n",
      "p\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.6 Get details of a tag\n",
    "\n",
    "# get the first p tag in the div of body\n",
    "div=list(body.children)[1]\n",
    "p=list(div.children)[1]\n",
    "p\n",
    "\n",
    "# get the details of p tag\n",
    "# first, get the data type of p\n",
    "print(\"\\ndata type:\")\n",
    "print(type(p))\n",
    "# get tag name (property of p object)\n",
    "print (\"\\ntag name: \")     \n",
    "print(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['inner-text', 'first-item'], 'id': 'first'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tag class: \n",
      "['inner-text', 'first-item']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n                First paragraph.\\n            '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a tag object with attributes has a dictionary. \n",
    "# use <tag>.attrs to get the dictionary\n",
    "# each attribute name of the tag is a key\n",
    "\n",
    "# get all attributes \n",
    "p.attrs\n",
    "\n",
    "# get \"class\" attribute\n",
    "print (\"\\ntag class: \")\n",
    "print(p[\"class\"])\n",
    "\n",
    "# how to determine if 'id' is an attribute of p?\n",
    "'id' in p.attrs\n",
    "# get text of p tag\n",
    "p.get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Navigating the html document tree ###\n",
    " \n",
    "* Going down\n",
    "  * <font color=\"green\">**contents**</font>: get a tag's direct children as a **list**\n",
    "  * <font color=\"green\">**children**</font>: get a tag's direct chidren as an **iterator**\n",
    "  * <font color=\"green\">**descendants**</font>:  get an iterator for a tag's all descendants, including direct children, the children of its direct children, and so on\n",
    "* Going up\n",
    "  * <font color=\"green\">**parent**</font>: get a tag's parent\n",
    "  * <font color=\"green\">**parents**</font>: get an iterator for a tag's ancestors, from the parent to the very top of the document\n",
    "* Going sideways\n",
    "  * <font color=\"green\">**next_sibling, next_siblings**</font>: get a tag's next sibling\n",
    "  * <font color=\"green\">**previous_sibling, previous_siblings**</font>: get a tag's previous sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get siblings of the first p tag\n",
      "['\\n', <p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>, '\\n']\n",
      "\n",
      "get the 2nd p tag\n",
      "<p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>\n"
     ]
    }
   ],
   "source": [
    " # Exercise 5.2.1  get siblings of p object\n",
    "print(\"\\nget siblings of the first p tag\")\n",
    "print(list(p.next_siblings))\n",
    "\n",
    "# get next p tag within the div\n",
    "# get the sibling next to the next sibling of p\n",
    "print(\"\\nget the 2nd p tag\")\n",
    "print(p.next_sibling.next_sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `find_all()`: Looks through a tag’s descendants and retrieves all descendants that match filters (https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all). A few examples:\n",
    "    * By tag name: `soup.find_all(\"title\")`\n",
    "    * By list of tag names: `soup.find_all([\"p\", \"title\"])`\n",
    "    * By attribtue: `soup.find_all(class_=\"inner-text\")`\n",
    "    * By attribtues: `data_soup.find_all(attrs={\"class\": \"inner-text\", \"id\":\"first\"})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>A simple example page</title>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>A simple example page</title>,\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all([\"p\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class is an attribute. \n",
    "# Since \"class\" is reserved, \n",
    "# use \"class_\" here\n",
    "soup.find_all(class_=\"inner-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(attrs={\"class\": \"inner-text\", \"id\":\"first\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.  Select tags into a list by CSS Selectors: select ###\n",
    "* CSS selectors used by CSS language to specify HTML tags to style\n",
    "* Originally, CSS selectors are patterns used to select elements for styling. \n",
    "* CSS selectors can be used to **choose html elements by node path**\n",
    "* List of patterns can be found at https://www.w3schools.com/cssref/css_selectors.asp\n",
    "* Some examples:\n",
    "  1. `div p` – finds all <font color=\"green\">p</font> tags inside a <font color=\"green\">div</font> tag.\n",
    "  2. `body p b` – finds all <font color=\"green\">b</font> tags inside a <font color=\"green\">p</font> tags within a <font color=\"green\">body</font> tag\n",
    "  3. `p.outer-text` – finds all <font color=\"green\">p</font> tags with a <font color=\"green\">class</font> of **outer-text**.\n",
    "  4. `p#first` – finds all <font color=\"green\">p</font> tags with an <font color=\"green\">id</font> attribute of **first**\n",
    "  5. `p[class=outer-text]` – finds all <font color=\"green\">p</font> tags with a class attribute that is **exactly** \"outer-text\" (no other class). Note [ ] is the generic way to define a filter on any attribute. \".\" is just for \"class\" attribute.\n",
    "  6. `p[class~=outer-text]` – finds all <font color=\"green\">p</font> tags  with a class attribute that **contains** a value \"outer-text\" (it may contain other values too, equivalent to p.outer-text). \n",
    "  7. `body p.outer-text b` – finds any <font color=\"green\">b</font> tags within <font color=\"green\">p</font> tags with a <font color=\"green\">class</font> of **outer-text** inside of a <font color=\"green\">body</font> tag.\n",
    "  8. `div, p` – finds all <font color=\"green\">div</font> and <font color=\"green\">p</font> tags (without nesting relationships). Compare it with example #1!\n",
    "  9. `p.outer-text.first-item` – finds all <font color=\"green\">p</font> tags  with **both class attribute \"outer-text\" and \"first-item\"**.\n",
    "  10. What about finding all p with class \"outer-text\" but not class \"first-item\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.1: select p tags within body tags\n",
    "# Notice the space between body and p\n",
    "# This means p is a **descendant** of body \n",
    "# p is not necessarily a direct child of body\n",
    "soup.select(\"body p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>\n",
       "                 First outer paragraph.\n",
       "             </b>,\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.2.: select b tags within p tags in the body\n",
    "soup.select(\"body p b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.3.: finds all p tags with a class of outer-text\n",
    "soup.select(\"p.outer-text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.4.: select p tags with id \"first\"\n",
    "soup.select(\"p#first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.5.:find p tag within body and\n",
    "# with a class attribute which is **exactly** \"outer-text\"\n",
    "\n",
    "# Note: this is the generic way to set  \n",
    "# a filter on any attribute\n",
    "\n",
    "soup.select(\"body p[class=outer-text]\")\n",
    "\n",
    "\n",
    "# compare the result with # Exercise 2.6.3.\n",
    "# how to select a line (i.e. tag \"a\") with a specific target, \n",
    "#   for example, http://www.stevens.edu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.6. find p tag with body \n",
    "# which has a class attribute **containing** a value \"out-text\"\n",
    "# Note the use of \"~\". \n",
    "\n",
    "soup.select(\"body p[class~=outer-text]\")\n",
    "\n",
    "# This is equivalent to soup.select(\"body p.outer-text\")\n",
    "# However, it's a generic way to set condition \n",
    "# on any type of attributes, not just \"class\" attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>\n",
       "                 First outer paragraph.\n",
       "             </b>,\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.7. select b tags within \n",
    "# p tags which have a class outer-text and \n",
    "# are within the body tag\n",
    "\n",
    "soup.select(\"body p.outer-text b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div>\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>\n",
       " </div>,\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.8. select all div and p tags \n",
    "# Compare the result with Exercise 2.6.1.\n",
    "# \",\" between tags means \"and/or\", \n",
    "# while \" \" (space) between tags means \"descendant\"\n",
    "\n",
    "soup.select(\"div, p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.9. select p tags \n",
    "# with two classes: outer-text and first-item\n",
    "soup.select(\"p.outer-text.first-item\")\n",
    "\n",
    "# what if another class, say \"xxx\" also required?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.10 finding all p tags with class \n",
    "# \"outer-text\" \n",
    "# but not class \"first-item\"\n",
    "soup.select(\"p.outer-text:not(.first-item)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.  Example: downloading weather forecast for the next week for New York City ###\n",
    "- Instruction:\n",
    "    1. Open web site http://forecast.weather.gov/MapClick.php?lat=40.7146&lon=-74.0071#.WXi6hlGQzIU and inspect page source\n",
    "    2. Find \"Extended Forecast for\" in the source code\n",
    "    3. Extract div tags in this section using \"seven-day-forecast-body div ul li div.tombstone-container\"\n",
    "       * Notice that the div under \"Extended Forecast for\" is what we need\n",
    "       * Follow the path to weather forecast for each period\n",
    "       <img src='weather.png' width='100%'>\n",
    "    4. For each div tag, extract text in different p tags and represent the result as a tuple, e.g. (\"Today\", \"Mostly Sunny\", \"High: 75F\"). Save the 7-day forecast as a list and print the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tonight', 'Mostly Cloudy', 'Low: 37 °F')\n",
      "('Sunday', 'Cloudy', 'High: 49 °F')\n",
      "('SundayNight', 'Mostly Cloudy', 'Low: 46 °F')\n",
      "(\"Washington'sBirthday\", 'Cloudy thenSlight ChanceShowers', 'High: 55 °F')\n",
      "('MondayNight', 'Mostly Cloudy', 'Low: 40 °F')\n",
      "('Tuesday', 'ChanceShowers', 'High: 52 °F')\n",
      "('TuesdayNight', 'Partly Cloudy', 'Low: 41 °F')\n",
      "('Wednesday', 'Partly Sunnythen ChanceRain', 'High: 49 °F')\n",
      "('WednesdayNight', 'Rain Likely', 'Low: 42 °F')\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2.7.1. downloading weather forecast for the next week for New York City \n",
    "\n",
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=40.7146&lon=-74.0071#.WXi6hlGQzIU\")    # send a get request to the web page\n",
    "rows=[]\n",
    "\n",
    "# status_code 200 indicates success. \n",
    "#a status code >200 indicates a failure \n",
    "if page.status_code==200:        \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # find a block with id='seven-day-forecast-body'\n",
    "    # follow the path down to the div for each period\n",
    "    divs=soup.select(\"div#seven-day-forecast-body \\\n",
    "    div ul li div.tombstone-container\")\n",
    "    #print len(divs)\n",
    "    #print divs\n",
    "    \n",
    "    for idx, div in enumerate(divs):\n",
    "        # for testing you can print idx, div\n",
    "        #print idx, div \n",
    "        \n",
    "        # initiate the variable for each period\n",
    "        title=None\n",
    "        desc=None\n",
    "        temp=None\n",
    "        \n",
    "        # get title\n",
    "        p_title=div.select(\"p.period-name\")\n",
    "        \n",
    "        # test if \"period-name\" indeed exists\n",
    "        # before you get the text\n",
    "        if p_title!=[]:\n",
    "            title=p_title[0].get_text()\n",
    "        \n",
    "        # get description\n",
    "        p_desc=div.select(\"p.short-desc\")\n",
    "        if p_desc!=[]:\n",
    "            desc=p_desc[0].get_text()\n",
    "        \n",
    "        # get temperature\n",
    "        p_temp=div.select(\"p.temp\")\n",
    "        if p_temp!=[]:\n",
    "            temp=p_temp[0].get_text()\n",
    "            \n",
    "        # add title, description, and temperature as a tuple into the list\n",
    "        rows.append((title, desc, temp))\n",
    "        print((title, desc, temp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we do it in this alternative way?, i.e.,\n",
    "\n",
    "- first retrieve all period names at one time, \n",
    "- then retrieve all temperatures at one time, \n",
    "- ...\n",
    "- and finally zip all of them\n",
    "\n",
    "\n",
    "Think about what will happen if one item (e.g., temperature) has missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'select' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/16/sj7htwpn37x5chbjt67h8nrr0000gn/T/ipykernel_2164/69342877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'p period.names'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p.temp.temp_low'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'select' is not defined"
     ]
    }
   ],
   "source": [
    "x1 = select ('p period.names')\n",
    "x2 = select('p.temp.temp_low')\n",
    "zip(x1,x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low: 37 °F', 'High: 49 °F', 'Low: 46 °F', 'High: 55 °F', 'Low: 40 °F', 'High: 52 °F', 'Low: 41 °F', 'High: 49 °F', 'Low: 42 °F']\n",
      "['Tonight', 'Sunday', 'SundayNight', \"Washington'sBirthday\", 'MondayNight', 'Tuesday', 'TuesdayNight', 'Wednesday', 'WednesdayNight']\n",
      "['Mostly Cloudy', 'Cloudy', 'Mostly Cloudy', 'Cloudy thenSlight ChanceShowers', 'Mostly Cloudy', 'ChanceShowers', 'Partly Cloudy', 'Partly Sunnythen ChanceRain', 'Rain Likely']\n",
      "[('Low: 37 °F', 'Tonight', 'Mostly Cloudy'), ('High: 49 °F', 'Sunday', 'Cloudy'), ('Low: 46 °F', 'SundayNight', 'Mostly Cloudy'), ('High: 55 °F', \"Washington'sBirthday\", 'Cloudy thenSlight ChanceShowers'), ('Low: 40 °F', 'MondayNight', 'Mostly Cloudy'), ('High: 52 °F', 'Tuesday', 'ChanceShowers'), ('Low: 41 °F', 'TuesdayNight', 'Partly Cloudy'), ('High: 49 °F', 'Wednesday', 'Partly Sunnythen ChanceRain'), ('Low: 42 °F', 'WednesdayNight', 'Rain Likely')]\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=40.7146&lon=-74.0071#.WXi6hlGQzIU\")    # send a get request to the web page\n",
    "rows=[]\n",
    "\n",
    "\n",
    "if page.status_code==200:        \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # find all temperature entries at one time\n",
    "    temps = []\n",
    "    divs_temp=soup.select(\"div#seven-day-forecast ul#seven-day-forecast-list li p.temp\")\n",
    "   \n",
    "    for d in divs_temp:\n",
    "        temps.append(d.get_text())\n",
    "    \n",
    "    print(temps)\n",
    "    # find all period names\n",
    "    pn = soup.select(\"div#seven-day-forecast ul#seven-day-forecast-list li p.period-name \")\n",
    "    periodname =[]\n",
    "    for p in pn:\n",
    "        periodname.append(p.get_text())\n",
    "    print(periodname)\n",
    "    \n",
    "    # find all short text\n",
    "    pn = soup.select(\"div#seven-day-forecast ul#seven-day-forecast-list li p.short-desc\")\n",
    "    shorttext =[]\n",
    "    for p in pn:\n",
    "        shorttext.append(p.get_text())\n",
    "    print(shorttext)\n",
    "    \n",
    "    # then zip all lists\n",
    "    print(list(zip(temps, periodname, shorttext)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scrapy and XPath\n",
    "- Another excellent library for web scraping\n",
    "- It supports both XPath and CSS selector\n",
    "- For details, check: https://docs.scrapy.org/en/latest/intro/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")    \n",
    "\n",
    "# status_code 200 indicates success. \n",
    "# a status code >200 indicates a failure\n",
    "if page.status_code==200:   \n",
    "    \n",
    "    sel = Selector(text = page.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p class=\"inner-text first-item\" id=\"first\">\\n                First paragraph.\\n            </p>',\n",
       " '<p class=\"inner-text\">\\n                Second paragraph.\\n            </p>',\n",
       " '<p class=\"outer-text first-item\" id=\"second\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>',\n",
       " '<p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['<p class=\"inner-text first-item\" id=\"first\">\\n                First paragraph.\\n            </p>',\n",
       " '<p class=\"inner-text\">\\n                Second paragraph.\\n            </p>',\n",
       " '<p class=\"outer-text first-item\" id=\"second\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>',\n",
       " '<p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.select(\"body p\")\n",
    "\n",
    "sel.xpath('//body//p').extract()  # XPath selector\n",
    "\n",
    "sel.css(\"body p\").extract()  # CSS selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p class=\"outer-text first-item\" id=\"second\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>',\n",
       " '<p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['<p class=\"outer-text first-item\" id=\"second\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>',\n",
       " '<p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.select(\"p.outer-text\")\n",
    "# soup.select(\"body p[class~=outer-text]\")\n",
    "\n",
    "sel.xpath('//p[contains(@class,\"outer-text\")]').extract()\n",
    "\n",
    "sel.css(\"p.outer-text\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p class=\"inner-text first-item\" id=\"first\">\\n                First paragraph.\\n            </p>']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['<p class=\"inner-text first-item\" id=\"first\">\\n                First paragraph.\\n            </p>']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.select(\"p#first\")\n",
    "\n",
    "sel.xpath('//p[@id=\"first\"]').extract()\n",
    "\n",
    "sel.css(\"p#first\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['<p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.select(\"body p[class=outer-text]\")\n",
    "\n",
    "sel.xpath('//body//p[@class=\"outer-text\"]').extract()\n",
    "\n",
    "sel.css(\"body p[class=outer-text]\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p class=\"outer-text first-item\" id=\"second\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['<p class=\"outer-text first-item\" id=\"second\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.select(\"p.outer-text.first-item\")\n",
    "\n",
    "sel.xpath('//body//p[contains(@class,\"outer-text\") and \\\n",
    "                     contains(@class,\"first-item\")]').extract()\n",
    "\n",
    "sel.css(\"p.outer-text.first-item\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use Selenium to request dynamic pages\n",
    "\n",
    "- Many websites uses server-side or client-side javascript to generate content in html pages\n",
    "- `Requests.get` can only retrieve the initial html source sent by the server, but html page is dynamically changing\n",
    "- The dynamic content cannot be retrieved\n",
    "- See https://www.w3schools.com/html/tryit.asp?filename=tryhtml_script for a simple example of dynamic content \n",
    "- Demo: https://silver-marleen-89.tiiny.site/\n",
    "    - See if you can script \"Hellp Java Script\" in the `p` tag: `<p id=\"demo\">Hello JavaScript!</p>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p tag [<p id=\"demo\"></p>]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://silver-marleen-89.tiiny.site/\"\n",
    "page = requests.get(url)   \n",
    "\n",
    "if page.status_code==200:    \n",
    "    \n",
    "    #print(page.content)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    print(\"p tag\", soup.select(\"p#demo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the html code retrieved by requests. Note that `<p id=\"demo\">` has no content yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <body>\n",
      "  <h2>\n",
      "   Use JavaScript to Change Text\n",
      "  </h2>\n",
      "  <p>\n",
      "   This example writes \"Hello JavaScript!\" into an HTML element with id=\"demo\":\n",
      "  </p>\n",
      "  <p id=\"demo\">\n",
      "  </p>\n",
      "  <script>\n",
      "   document.getElementById(\"demo\").innerHTML = \"Hello JavaScript!\";\n",
      "  </script>\n",
      "  <script data-domain=\"silver-marleen-89.tiiny.site\" defer=\"\" src=\"https://analytics.tiiny.site/js/plausible.js\">\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try Selenium. More details will be given later.\n",
    "\n",
    "- Selenium WebDriver is one of the most popular tools for **Web UI Automation**\n",
    "- It can control a web browser, like Chrome, Firefox or Safari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.8.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting trio~=0.17\n",
      "  Using cached trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from selenium) (2022.9.24)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.11)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Using cached trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: idna in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: sortedcontainers in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/apple/opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Installing collected packages: outcome, exceptiongroup, async-generator, trio, trio-websocket, selenium\n",
      "Successfully installed async-generator-1.10 exceptiongroup-1.1.0 outcome-1.2.0 selenium-4.8.0 trio-0.22.0 trio-websocket-0.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/16/sj7htwpn37x5chbjt67h8nrr0000gn/T/ipykernel_69813/228384324.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Firefox(executable_path=executable_path)\n"
     ]
    },
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: Expected browser binary location, but unable to find binary in default location, no 'moz:firefoxOptions.binary' capability provided, and no binary flag set on the command line\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/16/sj7htwpn37x5chbjt67h8nrr0000gn/T/ipykernel_69813/228384324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# start webdriver. Notice a firefox window pops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFirefox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# navigate to the page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/firefox/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, firefox_profile, firefox_binary, capabilities, proxy, executable_path, options, service_log_path, service_args, service, desired_capabilities, log_path, keep_alive)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mremote_server_addr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_proxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore_local_proxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         )\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_alive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mw3c_caps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_w3c_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw3c_caps\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"sessionId\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mSessionNotCreatedException\u001b[0m: Message: Expected browser binary location, but unable to find binary in default location, no 'moz:firefoxOptions.binary' capability provided, and no binary flag set on the command line\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# Locate web driver for firefox\n",
    "executable_path = 'driver/geckodriver'\n",
    "\n",
    "# start webdriver. Notice a firefox window pops\n",
    "driver = webdriver.Firefox(executable_path=executable_path)\n",
    "\n",
    "# navigate to the page\n",
    "driver.get(url)\n",
    "\n",
    "# now get the page content dynamically generated\n",
    "page = driver.page_source\n",
    "\n",
    "# parse the content by beautifulsoup \n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "#time.sleep(3)\n",
    "    \n",
    "print(\"p tag\", soup.select(\"p#demo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <body>\n",
      "  <h2>\n",
      "   Use JavaScript to Change Text\n",
      "  </h2>\n",
      "  <p>\n",
      "   This example writes \"Hello JavaScript!\" into an HTML element with id=\"demo\":\n",
      "  </p>\n",
      "  <p id=\"demo\">\n",
      "  </p>\n",
      "  <script>\n",
      "   document.getElementById(\"demo\").innerHTML = \"Hello JavaScript!\";\n",
      "  </script>\n",
      "  <script data-domain=\"silver-marleen-89.tiiny.site\" defer=\"\" src=\"https://analytics.tiiny.site/js/plausible.js\">\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
