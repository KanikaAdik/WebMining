{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aca36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "web scraping functionality from www.indeed.com (USA)\n",
    "\"\"\"\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "source = \"indeed.com\"\n",
    "cookies = {'aep_usuc_f': 'region=US&site=glo&b_locale=en_US&c_tp=USD'}\n",
    "\n",
    "\n",
    "def get_url(position):\n",
    "    \"\"\"\n",
    "    Generate URL from position and company type: recruiter or direct employer; education level\n",
    "    \"\"\"\n",
    "    url = f\"https://indeed.com/jobs?q={position}\"\n",
    "\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_job_date(card):\n",
    "    \"\"\"\n",
    "     extracts date from the job post record\n",
    "    :param card:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    post_str = card.find('span', {'class': 'date'}).text  # text from the footer: days ago was posted\n",
    "    post_days = re.findall(r'\\d+', post_str)  # extracting number of days from posted_str\n",
    "\n",
    "    if post_days:\n",
    "        # calculated date of job posting if days are mentioned\n",
    "        job_date = (datetime.now() - timedelta(days=int(post_days[0]))).strftime(\"%d/%m/%Y\")\n",
    "    else:\n",
    "        job_date = datetime.now().strftime(\"%d/%m/%Y\")  # if days are not mentioned - using today\n",
    "\n",
    "    return job_date\n",
    "\n",
    "\n",
    "def get_job_salaries(card):\n",
    "    \"\"\"\n",
    "    extracts salaries\n",
    "    :param card:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        salary_str = card.find('div', 'metadata salary-snippet-container').text\n",
    "        salaries = re.findall(r\"\\b(\\w+[.]\\w+)\", salary_str)\n",
    "\n",
    "    except AttributeError:\n",
    "        salaries = []\n",
    "\n",
    "    return salaries\n",
    "\n",
    "\n",
    "def get_record(card):\n",
    "    \"\"\"\n",
    "    Extract job data from a single record\n",
    "    \"\"\"\n",
    "    span_tag = card.h2.a.span\n",
    "    a_tag = card.h2.a\n",
    "\n",
    "    job_id = a_tag.get(\"data-jk\")  # unique job id\n",
    "    job_title = span_tag.get(\"title\")  # job title\n",
    "    job_url = 'https://www.indeed.com' + a_tag.get('href')  # job url\n",
    "    company_name = card.find('span', {'class': 'companyName'}).text  # company name\n",
    "    job_loc = card.find('div', {'class': 'companyLocation'}).text  # job location\n",
    "    job_summary = card.find('div', {'class': 'job-snippet'}).text.strip()  # job description\n",
    "    job_date = get_job_date(card)  # job posting date\n",
    "    job_salary = get_job_salaries(card)  # job salaries if any\n",
    "\n",
    "    record = (job_id, job_title, job_date, job_loc, job_summary, job_salary, job_url, company_name)\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "def get_jobs(position):\n",
    "    \"\"\"\n",
    "    creates a DataFrame with all records (scraped jobs), scraping from all pages\n",
    "    \"\"\"\n",
    "\n",
    "    url = get_url(position)\n",
    "    records = []\n",
    "\n",
    "    # extract the job data\n",
    "\n",
    "    while True:\n",
    "\n",
    "        response = \"\"\n",
    "        while response == \"\":\n",
    "            try:\n",
    "                response = requests.get(url=url, cookies=cookies)\n",
    "                break\n",
    "            except ConnectionError:\n",
    "                print(\"Connection refused by the server..\")\n",
    "                print(\"Let me sleep for 5 seconds\")\n",
    "                print(\"ZZzzzz...\")\n",
    "                time.sleep(5)\n",
    "                print(\"Was a nice sleep, now let me continue...\")\n",
    "                continue\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        cards = soup.find_all('div', 'job_seen_beacon')\n",
    "\n",
    "        for card in cards:\n",
    "            print(card)\n",
    "            record = get_record(card)\n",
    "            records.append(record)\n",
    "\n",
    "        time.sleep(3)  # making a pause before moving to the next page\n",
    "\n",
    "        # moving to the next page - > assigning a new url\n",
    "        try:\n",
    "            url = 'https://indeed.com/' + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "\n",
    "        except AttributeError:\n",
    "            break\n",
    "\n",
    "    # save the data as DF\n",
    "    columns = ['job_id',\n",
    "               'job_title',\n",
    "               'job_date',\n",
    "               'job_loc',\n",
    "               'job_summary',\n",
    "               'job_salary',\n",
    "               'job_url',\n",
    "               'company_name']\n",
    "    df = pd.DataFrame(data=records, columns=columns)\n",
    "\n",
    "    # adding to DF columns with search parameters\n",
    "    search_time = datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "\n",
    "    df[\"search_time\"] = search_time\n",
    "    df[\"search_position\"] = position\n",
    "    df[\"source\"] = source\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbfa8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_jobs(\"accountant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5478127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_date</th>\n",
       "      <th>job_loc</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_salary</th>\n",
       "      <th>job_url</th>\n",
       "      <th>company_name</th>\n",
       "      <th>search_time</th>\n",
       "      <th>search_position</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_id, job_title, job_date, job_loc, job_summary, job_salary, job_url, company_name, search_time, search_position, source]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396914a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
