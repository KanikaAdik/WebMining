{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-warning\">Each assignment needs to be completed independently. Never ever copy others' work (even with minor modification, e.g. changing variable names). Anti-Plagiarism software will be used to check all submissions. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "In this assignment, we'll use what we learned in NLP module to compare ChatGPT-generated text with human-generated answers. A dataset with 200 questions and answers has been provided for you to use. The dataset can be found at https://huggingface.co/datasets/Hello-SimpleAI/HC3.\n",
    "\n",
    "\n",
    "Please follow the instruction below to do the assessment step by step and answer all analysis questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>chatgpt_answer</th>\n",
       "      <th>human_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happens if a parking ticket is lost / des...</td>\n",
       "      <td>If a parking ticket is lost or destroyed befor...</td>\n",
       "      <td>In my city you also get something by mail to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why the waves do n't interfere ? first , I 'm ...</td>\n",
       "      <td>Interference is the phenomenon that occurs whe...</td>\n",
       "      <td>They do actually . That 's why a microwave ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it possible to influence a company's action...</td>\n",
       "      <td>Yes, it is possible to influence a company's a...</td>\n",
       "      <td>Yes and no. This really should be taught at ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why do taxpayers front the bill for sports sta...</td>\n",
       "      <td>Sports stadiums are usually built with public ...</td>\n",
       "      <td>That 's the bargaining chip that team owners u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why do clothing stores generally have a ton of...</td>\n",
       "      <td>There are a few reasons why clothing stores ma...</td>\n",
       "      <td>Your observation is almost certainly a matter ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What happens if a parking ticket is lost / des...   \n",
       "1  why the waves do n't interfere ? first , I 'm ...   \n",
       "2  Is it possible to influence a company's action...   \n",
       "3  Why do taxpayers front the bill for sports sta...   \n",
       "4  Why do clothing stores generally have a ton of...   \n",
       "\n",
       "                                      chatgpt_answer  \\\n",
       "0  If a parking ticket is lost or destroyed befor...   \n",
       "1  Interference is the phenomenon that occurs whe...   \n",
       "2  Yes, it is possible to influence a company's a...   \n",
       "3  Sports stadiums are usually built with public ...   \n",
       "4  There are a few reasons why clothing stores ma...   \n",
       "\n",
       "                                        human_answer  \n",
       "0  In my city you also get something by mail to t...  \n",
       "1  They do actually . That 's why a microwave ove...  \n",
       "2  Yes and no. This really should be taught at ju...  \n",
       "3  That 's the bargaining chip that team owners u...  \n",
       "4  Your observation is almost certainly a matter ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"qa.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Tokenize function\n",
    "\n",
    "Define a function `tokenize(docs, lemmatized = True, remove_stopword = True, remove_punct = True)`  as follows:\n",
    "   - Take three parameters: \n",
    "       - `docs`: a list of documents (e.g. questions)\n",
    "       - `lemmatized`: an optional boolean parameter to indicate if tokens are lemmatized. The default value is True (i.e. tokens are lemmatized).\n",
    "       - `remove_stopword`: an optional bookean parameter to remove stop words. The default value is True (i.e. remove stop words). \n",
    "   - Split each input document into unigrams and also clean up tokens as follows:\n",
    "       - if `lemmatized` is turned on, lemmatize all unigrams.\n",
    "       - if `remove_stopword` is set to True, remove all stop words.\n",
    "       - if `remove_punct` is set to True, remove all punctuation tokens.\n",
    "       - remove all empty tokens and lowercase all the tokens.\n",
    "   - Return the list of tokens obtained for each document after all the processing. \n",
    "   \n",
    "(Hint: you can use spacy package for this task. For reference, check https://spacy.io/api/token#attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(docs, lemmatized=True, remove_stopword=True, remove_punct = True):\n",
    "    \n",
    "    tokenized_docs = []\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    return tokenized_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function with different parameter configuration and observe the differences in the resulting tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What happens if a parking ticket is lost / destroyed before the owner is aware of the ticket , and it goes unpaid ? I 've always been curious . Please explain like I'm five.\n",
      "\n",
      "1.lemmatized=True, remove_stopword=False, remove_punct = True:\n",
      " [['what', 'happen', 'if', 'a', 'parking', 'ticket', 'be', 'lost', 'destroy', 'before', 'the', 'owner', 'be', 'aware', 'of', 'the', 'ticket', 'and', 'it', 'go', 'unpaid', 'i', 've', 'always', 'be', 'curious', 'please', 'explain', 'like', 'i', 'be', 'five']]\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      " [['happen', 'parking', 'ticket', 'lost', 'destroy', 'owner', 'aware', 'ticket', 'go', 'unpaid', 've', 'curious', 'explain', 'like']]\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      " [['what', 'happens', 'if', 'a', 'parking', 'ticket', 'is', 'lost', 'destroyed', 'before', 'the', 'owner', 'is', 'aware', 'of', 'the', 'ticket', 'and', 'it', 'goes', 'unpaid', 'i', 've', 'always', 'been', 'curious', 'please', 'explain', 'like', 'i', \"'m\", 'five']]\n",
      "\n",
      "4.lemmatized=False, remove_stopword=False, remove_punct = False:\n",
      " [['what', 'happens', 'if', 'a', 'parking', 'ticket', 'is', 'lost', '/', 'destroyed', 'before', 'the', 'owner', 'is', 'aware', 'of', 'the', 'ticket', ',', 'and', 'it', 'goes', 'unpaid', '?', 'i', \"'\", 've', 'always', 'been', 'curious', '.', 'please', 'explain', 'like', 'i', \"'m\", 'five', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For simplicity, We will test one document\n",
    "\n",
    "print(data[\"question\"].iloc[0] + \"\\n\")\n",
    "\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=True, remove_stopword=False, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=True, remove_stopword=True, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"3.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=False, remove_stopword=False, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"4.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=False, remove_stopword=False, remove_punct = False)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Sentiment Analysis\n",
    "\n",
    "\n",
    "Let's check if there is any difference in sentiment between ChatGPT-generated and human-generated answers.\n",
    "\n",
    "\n",
    "Define a function `compute_sentiment(generated, reference, pos, neg )` as follows:\n",
    "- take four parameters:\n",
    "    - `gen_tokens` is the tokenized ChatGPT-generated answers by the `tokenize` function in Q1.\n",
    "    - `ref_tokens` is the tokenized human answers by the `tokenize` function in Q1.\n",
    "    - `pos` (`neg`) is the list of positive (negative) words, which can be find in Canvas NLP module.\n",
    "- for each ChatGPT-generated or human answer, compute the sentiment as `(#pos - #neg )/(#pos + #neg)`, where `#pos`(`#neg`) is the number of positive (negative) words found in each answer. If an answer contains none of the positive or negative words, set the sentiment to 0.\n",
    "- return the sentiment of ChatGPT-generated and human answers as two columns of DataFrame.\n",
    "\n",
    "\n",
    "Analysis: \n",
    "- Try different tokenization parameter configurations (lemmatized, remove_stopword, remove_punct), and observe how sentiment results change.\n",
    "- Do you think, in general, which tokenization configuration should be used? Why does this configuration make the most senese?\n",
    "- Do you think, overall, ChatGPT-generated answers are more posive or negative than human answers? Use data to support your conclusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment(gen_tokens, ref_tokens, pos, neg ):\n",
    "    \n",
    "    result = None\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tokens = tokenize(data[\"chatgpt_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "ref_tokens = tokenize(data[\"human_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abundance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abundant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0         a+\n",
       "1     abound\n",
       "2    abounds\n",
       "3  abundance\n",
       "4   abundant"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-faced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abolish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0     2-faced\n",
       "1     2-faces\n",
       "2    abnormal\n",
       "3     abolish\n",
       "4  abominable"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = pd.read_csv(\"../Notes/NLP/positive-words.txt\", header = None)\n",
    "pos.head()\n",
    "\n",
    "neg = pd.read_csv(\"../Notes/NLP/negative-words.txt\", header = None)\n",
    "neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_sentiment</th>\n",
       "      <th>ref_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.777778</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gen_sentiment  ref_sentiment\n",
       "0       0.000000      -0.500000\n",
       "1      -0.777778       0.076923\n",
       "2       0.666667       0.200000\n",
       "3       1.000000       0.200000\n",
       "4       0.600000      -0.333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_sentiment(gen_tokens, \n",
    "                           ref_tokens, \n",
    "                           pos[0].values,\n",
    "                           neg[0].values)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Performance Evaluation\n",
    "\n",
    "\n",
    "Next, we evaluate how accurate the ChatGPT-generated answers are, compared to the human-generated answers. One widely used method is to calculate the `precision` and `recall` of n-grams. For simplicity, we only calculate bigrams here. You can try unigram, trigram, or n-grams in the same way.\n",
    "\n",
    "\n",
    "Define a funtion `bigram_precision_recall(gen_tokens, ref_tokens)` as follows:\n",
    "- take two parameters:\n",
    "    - `gen_tokens` is the tokenized ChatGPT-generated answers by the `tokenize` function in Q1.\n",
    "    - `ref_tokens` is the tokenized human answers by the `tokenize` function in Q1.\n",
    "- generate bigrams from each tokenized document in `gen_tokens` and `ref_tokens`.\n",
    "- for each pair of ChatGPT-generated and human answers: \n",
    "    - find the overlapping bigrams between them.\n",
    "    - compute `precision` as the number of overlapping bigrams divided by the total number of bigrams from the ChatGPT-generated answer. In other words, the bigram in the ChatGPT-generated answer is considered as a predicted value. The `precision` measures the percentage of correctly generated bigrams out of all the generated bigrams.\n",
    "    - compute `recall` as the number of overlapping bigrams divided by the total number of bigrams from the human answer. In other words, the `recall` measures the percentage of bigrams from the human answer can be successfully retrieved.\n",
    "- return the precision and recall for each pair of answers.\n",
    "\n",
    "\n",
    "Analysis: \n",
    "- Try different tokenization parameter configurations (lemmatized, remove_stopword, remove_punct), and observe how precison and recall change.\n",
    "- Which tokenization configuration can render the highest average precision and recall scores across all questions?\n",
    "- Do you think, overall, ChatGPT is able to mimic human in answering these questions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_precision_recall(gen_tokens, ref_tokens):\n",
    "    \n",
    "    result = None\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overlapping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(it, goes), (to, pay)]</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(can, cancel), (out, of), (radio, stations), ...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.015695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(to, influence), (a, company), (to, vote), (t...</td>\n",
       "      <td>0.143885</td>\n",
       "      <td>0.060423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(to, be), (the, local), (be, the)]</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(., as), (as, a), (a, result), (result, ,), (...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.072165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         overlapping  precision    recall\n",
       "0                            [(it, goes), (to, pay)]   0.016807  0.042553\n",
       "1  [(can, cancel), (out, of), (radio, stations), ...   0.033333  0.015695\n",
       "2  [(to, influence), (a, company), (to, vote), (t...   0.143885  0.060423\n",
       "3                [(to, be), (the, local), (be, the)]   0.017647  0.051724\n",
       "4  [(., as), (as, a), (a, result), (result, ,), (...   0.028571  0.072165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = bigram_precision_recall(gen_tokens, \n",
    "                                 ref_tokens)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Compute TF-IDF\n",
    "\n",
    "Define a function `compute_tf_idf(tokenized_docs)` as follows: \n",
    "- Take paramter `tokenized_docs`, i.e., a list of tokenized documents by `tokenize` function in Q1\n",
    "- Calculate tf_idf weights as shown in lecture notes (Hint: feel free to reuse the code segment in NLP Lecture Notes (II))\n",
    "- Return the smoothed normalized `tf_idf` array, where each row stands for a document and each column denotes a word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(tokenized_docs):\n",
    "    \n",
    "    smoothed_tf_idf = None\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    return smoothed_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different tokenization options to see how these options affect TFIDF matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.lemmatized=True, remove_stopword=False, remove_punct = True:\n",
      " Shape: (200, 1439)\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      " Shape: (200, 1268)\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      " Shape: (200, 1643)\n",
      "\n",
      "4.lemmatized=False, remove_stopword=False, remove_punct = False:\n",
      " Shape: (200, 1665)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test tfidf generation using questions\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=True, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"3.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"4.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Assess similarity. \n",
    "\n",
    "\n",
    "Define a function `assess_similarity(question_tokens, gen_tokens, ref_tokens)`  as follows: \n",
    "- Take three inputs:\n",
    "   - `question_tokens`: tokenized questions by `tokenize` function in Q1\n",
    "   - `gen_tokens`: tokenized ChatGPT-generated answers by `tokenize` function in Q1\n",
    "   - `ref_tokens`: tokenized human answers by `tokenize` function in Q1\n",
    "- Concatenate these three token lists into a single list to form a corpus\n",
    "- Calculate the smoothed normalized tf_idf matrix for the concatenated list using the `compute_tfidf` function defined in Q3.\n",
    "- Split the tf_idf matrix into sub-matrices corresponding to `question_tokens`, `gen_tokens`, and `ref_tokens` respectively\n",
    "- For each question, find its similarities to the paired ChatGPT-generated answer and human answer.\n",
    "- For each pair of ChatGPT-generated answer and human answer, find their similarity\n",
    "- Print out the following:\n",
    "    - the question which has the largest similarity to the ChatGPT-generated answer.\n",
    "    - the question which has the largest similarity to the human answer.\n",
    "    - the pair of ChatGPT-generated and human answers which have the largest similarity.\n",
    "- Return a DataFrame with the three columns for the similarities among questions and answers.\n",
    "\n",
    "\n",
    "\n",
    "Analysis: \n",
    "- Try different tokenization parameter configurations (lemmatized, remove_stopword, remove_punct), and observe how similarities change.\n",
    "- Based on similarity, do you think ChatGPT-generate answers are more (or less) relevant to questions than human answers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def assess_similarity(question_tokens, gen_tokens, ref_tokens):\n",
    "    \n",
    "    result = None\n",
    "    \n",
    "    # Add your code here\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question with the largest similarity to the ChatGPT-generated answer:\n",
      " Question: Where to find historical quotes for the Dow Jones Global Total Stock Market Index? \n",
      " ChatGPT: You can find historical quotes for the Dow Jones Global Total Stock Market Index at several financial websites, such as Yahoo Finance, Google Finance, and Bloomberg. These websites allow you to view the historical performance of the index and see how it has changed over time.To find historical quotes for the Dow Jones Global Total Stock Market Index on Yahoo Finance, go to the Yahoo Finance website and enter \"Dow Jones Global Total Stock Market Index\" in the search bar. From the search results, click on the link for the Dow Jones Global Total Stock Market Index. On the resulting page, you will be able to view the current value of the index as well as historical data dating back to the index's inception.To find historical quotes for the Dow Jones Global Total Stock Market Index on Google Finance, go to the Google Finance website and enter \"Dow Jones Global Total Stock Market Index\" in the search bar. From the search results, click on the link for the Dow Jones Global Total Stock Market Index. On the resulting page, you will be able to view the current value of the index as well as a chart showing its historical performance.To find historical quotes for the Dow Jones Global Total Stock Market Index on Bloomberg, go to the Bloomberg website and enter \"Dow Jones Global Total Stock Market Index\" in the search bar. From the search results, click on the link for the Dow Jones Global Total Stock Market Index. On the resulting page, you will be able to view the current value of the index as well as a chart showing its historical performance., \n",
      " Human: A number of places.  First, fast and cheap, you can probably get this from EODData.com, as part of a historical index price download -- they have good customer service in my experience and will likely confirm it for you before you buy.  Any number of other providers can get it for you too.  Likely Capital IQ, Bloomberg, and other professional solutions. I checked a number of free sites, and Market Watch was the only that had a longer history than a few months. \n",
      "\n",
      "question_ref_sim    0.111511\n",
      "question_gen_sim    0.782898\n",
      "gen_ref_sim         0.184920\n",
      "Name: 30, dtype: float64 \n",
      "\n",
      "Question with the largest similarity to the human answer:\n",
      " Question: when the wind blows james patterson \n",
      " ChatGPT: \"When the Wind Blows\" is a novel by James Patterson, published in 1996. The book is a suspense thriller that follows a couple, Frannie and Kit, as they try to uncover the truth behind a series of strange and terrifying events that occur in their small town. The novel explores themes of government conspiracy, environmentalism, and the dangers of technology. It is the first book in the \"Maximum Ride\" series, which follows the adventures of a group of genetically enhanced young people known as the \"Flock,\" who have the ability to fly., \n",
      " Human: When the Wind Blows is a novel by James Patterson . \n",
      "\n",
      "question_ref_sim    0.871841\n",
      "question_gen_sim    0.253087\n",
      "gen_ref_sim         0.353696\n",
      "Name: 117, dtype: float64 \n",
      "\n",
      "Question with the largest similarity between ChatGPT-generated and human answers:\n",
      " Question: what was the date of pearl harbor \n",
      " ChatGPT: The attack on Pearl Harbor occurred on December 7, 1941. It was a surprise military strike by the Imperial Japanese Navy against the United States naval base at Pearl Harbor, Hawaii. The attack led to the United States entering World War II., \n",
      " Human: The attack on Pearl Harbor (called Hawaii Operation or Operation AI by the Japanese Imperial General Headquarters (Operation Z in planning) and the Battle of Pearl Harbor) was a surprise military strike conducted by the Imperial Japanese Navy against the United States naval base at Pearl Harbor , Hawaii, on the morning of December 7, 1941 (December 8 in Japan). \n",
      "\n",
      "question_ref_sim    0.419917\n",
      "question_gen_sim    0.397606\n",
      "gen_ref_sim         0.682076\n",
      "Name: 122, dtype: float64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_ref_sim</th>\n",
       "      <th>question_gen_sim</th>\n",
       "      <th>gen_ref_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125593</td>\n",
       "      <td>0.570514</td>\n",
       "      <td>0.171820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136946</td>\n",
       "      <td>0.535158</td>\n",
       "      <td>0.265380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198697</td>\n",
       "      <td>0.464419</td>\n",
       "      <td>0.451627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140980</td>\n",
       "      <td>0.418178</td>\n",
       "      <td>0.349791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177977</td>\n",
       "      <td>0.285982</td>\n",
       "      <td>0.142059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_ref_sim  question_gen_sim  gen_ref_sim\n",
       "0          0.125593          0.570514     0.171820\n",
       "1          0.136946          0.535158     0.265380\n",
       "2          0.198697          0.464419     0.451627\n",
       "3          0.140980          0.418178     0.349791\n",
       "4          0.177977          0.285982     0.142059"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once case is tested here. \n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "gen_tokens = tokenize(data[\"chatgpt_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "ref_tokens = tokenize(data[\"human_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "\n",
    "result = assess_similarity(question_tokens, gen_tokens, ref_tokens)\n",
    "result.head()\n",
    "\n",
    "# You need to test other cases so that you can answer the analysis questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 (Bonus): Further Analysis (Open question)\n",
    "\n",
    "\n",
    "- Can you find at least three significant differences between ChatGPT-generated and human answeres? Use data to support your answer.\n",
    "- Based on these differences, are you able to design a classifier to identify ChatGPT generated answers? Implement your ideas using traditional machine learning models, such as SVM, decision trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Please move all your unit tests into the main block to make grading easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test queston 1:\n",
    "    question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "    gen_tokens = tokenize(data[\"chatgpt_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "    ref_tokens = tokenize(data[\"human_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "    \n",
    "    # Test question 2\n",
    "    pos = pd.read_csv(\"../Notes/NLP/positive-words.txt\", header = None)\n",
    "    neg = pd.read_csv(\"../Notes/NLP/negative-words.txt\", header = None)\n",
    "\n",
    "    result = compute_sentiment(gen_tokens, \n",
    "                           ref_tokens, \n",
    "                           pos[0].values,\n",
    "                           neg[0].values)\n",
    "    print(result.head())\n",
    "    \n",
    "    # Test question 3\n",
    "    result = bigram_precision_recall(gen_tokens, \n",
    "                                 ref_tokens)\n",
    "    print(result.head())\n",
    "    \n",
    "    \n",
    "    # Test question 4\n",
    "    dtm = compute_tfidf(question_tokens)\n",
    "    print(f\"1.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "    Shape: {dtm.shape}\\n\")\n",
    "    \n",
    "    # Test question 5\n",
    "    result = assess_similarity(question_tokens, gen_tokens, ref_tokens)\n",
    "    print(result.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
