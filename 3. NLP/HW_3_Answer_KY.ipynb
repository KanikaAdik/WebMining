{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1v2oU4Ic9EA"
   },
   "source": [
    "# HW3: Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMuKUmb7c9EB"
   },
   "source": [
    " <div class=\"alert alert-block alert-warning\">Each assignment needs to be completed independently. Never ever copy others' work (even with minor modification, e.g. changing variable names). Anti-Plagiarism software will be used to check all submissions. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rvlxo5pCc9EB"
   },
   "source": [
    "## Problem Description\n",
    "\n",
    "In this assignment, we'll use what we learned in NLP module to compare ChatGPT-generated text with human-generated answers. A dataset with 200 questions and answers has been provided for you to use. The dataset can be found at https://huggingface.co/datasets/Hello-SimpleAI/HC3.\n",
    "\n",
    "\n",
    "Please follow the instruction below to do the assessment step by step and answer all analysis questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6AizdosDc9EB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eFhvBH2Ac9EC",
    "outputId": "e36bdf25-33ff-41fa-bef2-cf6e8c61d654"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>chatgpt_answer</th>\n",
       "      <th>human_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happens if a parking ticket is lost / des...</td>\n",
       "      <td>If a parking ticket is lost or destroyed befor...</td>\n",
       "      <td>In my city you also get something by mail to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why the waves do n't interfere ? first , I 'm ...</td>\n",
       "      <td>Interference is the phenomenon that occurs whe...</td>\n",
       "      <td>They do actually . That 's why a microwave ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it possible to influence a company's action...</td>\n",
       "      <td>Yes, it is possible to influence a company's a...</td>\n",
       "      <td>Yes and no. This really should be taught at ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why do taxpayers front the bill for sports sta...</td>\n",
       "      <td>Sports stadiums are usually built with public ...</td>\n",
       "      <td>That 's the bargaining chip that team owners u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why do clothing stores generally have a ton of...</td>\n",
       "      <td>There are a few reasons why clothing stores ma...</td>\n",
       "      <td>Your observation is almost certainly a matter ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What happens if a parking ticket is lost / des...   \n",
       "1  why the waves do n't interfere ? first , I 'm ...   \n",
       "2  Is it possible to influence a company's action...   \n",
       "3  Why do taxpayers front the bill for sports sta...   \n",
       "4  Why do clothing stores generally have a ton of...   \n",
       "\n",
       "                                      chatgpt_answer  \\\n",
       "0  If a parking ticket is lost or destroyed befor...   \n",
       "1  Interference is the phenomenon that occurs whe...   \n",
       "2  Yes, it is possible to influence a company's a...   \n",
       "3  Sports stadiums are usually built with public ...   \n",
       "4  There are a few reasons why clothing stores ma...   \n",
       "\n",
       "                                        human_answer  \n",
       "0  In my city you also get something by mail to t...  \n",
       "1  They do actually . That 's why a microwave ove...  \n",
       "2  Yes and no. This really should be taught at ju...  \n",
       "3  That 's the bargaining chip that team owners u...  \n",
       "4  Your observation is almost certainly a matter ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"qa.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsxUYGVqc9EC"
   },
   "source": [
    "## Q1. Tokenize function\n",
    "\n",
    "Define a function `tokenize(docs, lemmatized = True, remove_stopword = True, remove_punct = True)`  as follows:\n",
    "   - Take three parameters: \n",
    "       - `docs`: a list of documents (e.g. questions)\n",
    "       - `lemmatized`: an optional boolean parameter to indicate if tokens are lemmatized. The default value is True (i.e. tokens are lemmatized).\n",
    "       - `remove_stopword`: an optional bookean parameter to remove stop words. The default value is True (i.e. remove stop words). \n",
    "   - Split each input document into unigrams and also clean up tokens as follows:\n",
    "       - if `lemmatized` is turned on, lemmatize all unigrams.\n",
    "       - if `remove_stopword` is set to True, remove all stop words.\n",
    "       - if `remove_punct` is set to True, remove all punctuation tokens.\n",
    "       - remove all empty tokens and lowercase all the tokens.\n",
    "   - Return the list of tokens obtained for each document after all the processing. \n",
    "   \n",
    "(Hint: you can use spacy package for this task. For reference, check https://spacy.io/api/token#attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mu08kGDec9EC",
    "outputId": "0143424f-f774-4a99-b1a8-a7c7c46f7a1d"
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CoLbWtSQc9EC"
   },
   "outputs": [],
   "source": [
    "def tokenize(docs, lemmatized=True, remove_stopword=True, remove_punct = True):   \n",
    "    tokenized_docs = []\n",
    "    for single_doc in docs:\n",
    "      doc = nlp(single_doc)\n",
    "      single_tokenized_docs =[]\n",
    "      for word in doc:\n",
    "        if lemmatized:\n",
    "          add_word = str(word.lemma_)\n",
    "        else:\n",
    "          add_word = str(word)\n",
    "        if remove_stopword:\n",
    "          if word.is_stop:\n",
    "            continue\n",
    "        if remove_punct:\n",
    "          if word.is_punct:\n",
    "            continue\n",
    "        single_tokenized_docs.append(add_word.lower())\n",
    "      tokenized_docs.append(single_tokenized_docs)\n",
    "    return tokenized_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "RTxOznhvdEq4",
    "outputId": "f52b5dde-96c0-4ecb-a799-d47daa310e68"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nprint(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n {tokenize(data[\\'question\\'].iloc[0:1], lemmatized=True, remove_stopword=False, remove_punct = True)}\\n\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.lemmatized=True, remove_stopword=False, remove_punct = True:\n",
      " [['what', 'happen', 'if', 'a', 'parking', 'ticket', 'be', 'lose', 'destroy', 'before', 'the', 'owner', 'be', 'aware', 'of', 'the', 'ticket', 'and', 'it', 'go', 'unpaid', 'i', 've', 'always', 'be', 'curious', 'please', 'explain', 'like', 'i', 'be', 'five']]\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      " [['happen', 'parking', 'ticket', 'lose', 'destroy', 'owner', 'aware', 'ticket', 'go', 'unpaid', 've', 'curious', 'explain', 'like']]\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      " [['what', 'happens', 'if', 'a', 'parking', 'ticket', 'is', 'lost', 'destroyed', 'before', 'the', 'owner', 'is', 'aware', 'of', 'the', 'ticket', 'and', 'it', 'goes', 'unpaid', 'i', 've', 'always', 'been', 'curious', 'please', 'explain', 'like', 'i', \"'m\", 'five']]\n",
      "\n",
      "4.lemmatized=False, remove_stopword=False, remove_punct = False:\n",
      " [['what', 'happens', 'if', 'a', 'parking', 'ticket', 'is', 'lost', '/', 'destroyed', 'before', 'the', 'owner', 'is', 'aware', 'of', 'the', 'ticket', ',', 'and', 'it', 'goes', 'unpaid', '?', 'i', \"'\", 've', 'always', 'been', 'curious', '.', 'please', 'explain', 'like', 'i', \"'m\", 'five', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For simplicity, We will test one document\n",
    "\n",
    "#print(data[\"question\"].iloc[0] + \"\\n\")\n",
    "\"\"\"\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=True, remove_stopword=False, remove_punct = True)}\\n\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=True, remove_stopword=False, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=True, remove_stopword=True, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"3.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=False, remove_stopword=False, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"4.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=False, remove_stopword=False, remove_punct = False)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC4n1_B-c9EC"
   },
   "source": [
    "Test your function with different parameter configuration and observe the differences in the resulting tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYQfX4mDc9ED",
    "outputId": "03319641-def1-4d46-f69d-7abb1cef1d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What happens if a parking ticket is lost / destroyed before the owner is aware of the ticket , and it goes unpaid ? I 've always been curious . Please explain like I'm five.\n",
      "\n",
      "1.lemmatized=True, remove_stopword=False, remove_punct = True:\n",
      " [['what', 'happen', 'if', 'a', 'parking', 'ticket', 'be', 'lose', 'destroy', 'before', 'the', 'owner', 'be', 'aware', 'of', 'the', 'ticket', 'and', 'it', 'go', 'unpaid', 'i', 've', 'always', 'be', 'curious', 'please', 'explain', 'like', 'i', 'be', 'five']]\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      " [['happen', 'parking', 'ticket', 'lose', 'destroy', 'owner', 'aware', 'ticket', 'go', 'unpaid', 've', 'curious', 'explain', 'like']]\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      " [['what', 'happens', 'if', 'a', 'parking', 'ticket', 'is', 'lost', 'destroyed', 'before', 'the', 'owner', 'is', 'aware', 'of', 'the', 'ticket', 'and', 'it', 'goes', 'unpaid', 'i', 've', 'always', 'been', 'curious', 'please', 'explain', 'like', 'i', \"'m\", 'five']]\n",
      "\n",
      "4.lemmatized=False, remove_stopword=False, remove_punct = False:\n",
      " [['what', 'happens', 'if', 'a', 'parking', 'ticket', 'is', 'lost', '/', 'destroyed', 'before', 'the', 'owner', 'is', 'aware', 'of', 'the', 'ticket', ',', 'and', 'it', 'goes', 'unpaid', '?', 'i', \"'\", 've', 'always', 'been', 'curious', '.', 'please', 'explain', 'like', 'i', \"'m\", 'five', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For simplicity, We will test one document\n",
    "\n",
    "print(data[\"question\"].iloc[0] + \"\\n\")\n",
    "\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=True, remove_stopword=False, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=True, remove_stopword=True, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"3.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=False, remove_stopword=False, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"4.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=False, remove_stopword=False, remove_punct = False)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_52G4f7c9ED"
   },
   "source": [
    "## Q2. Sentiment Analysis\n",
    "\n",
    "\n",
    "Let's check if there is any difference in sentiment between ChatGPT-generated and human-generated answers.\n",
    "\n",
    "\n",
    "Define a function `compute_sentiment(generated, reference, pos, neg )` as follows:\n",
    "- take four parameters:\n",
    "    - `gen_tokens` is the tokenized ChatGPT-generated answers by the `tokenize` function in Q1.\n",
    "    - `ref_tokens` is the tokenized human answers by the `tokenize` function in Q1.\n",
    "    - `pos` (`neg`) is the list of positive (negative) words, which can be find in Canvas NLP module.\n",
    "- for each ChatGPT-generated or human answer, compute the sentiment as `(#pos - #neg )/(#pos + #neg)`, where `#pos`(`#neg`) is the number of positive (negative) words found in each answer. If an answer contains none of the positive or negative words, set the sentiment to 0.\n",
    "- return the sentiment of ChatGPT-generated and human answers as two columns of DataFrame.\n",
    "\n",
    "\n",
    "Analysis: \n",
    "- Try different tokenization parameter configurations (lemmatized, remove_stopword, remove_punct), and observe how sentiment results change.\n",
    "- Do you think, in general, which tokenization configuration should be used? Why does this configuration make the most senese?\n",
    "- Do you think, overall, ChatGPT-generated answers are more posive or negative than human answers? Use data to support your conclusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3lU-Ynhuc9ED"
   },
   "outputs": [],
   "source": [
    "gen_tokens = tokenize(data[\"chatgpt_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "ref_tokens = tokenize(data[\"human_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "ktcGLYQtllzl",
    "outputId": "e2be5273-4dfb-4f20-e4e9-b95c53a3f3c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9a58f4a4-d65b-4dd3-b8dd-5a23bb96416f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abundance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abundant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a58f4a4-d65b-4dd3-b8dd-5a23bb96416f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9a58f4a4-d65b-4dd3-b8dd-5a23bb96416f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9a58f4a4-d65b-4dd3-b8dd-5a23bb96416f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           0\n",
       "0         a+\n",
       "1     abound\n",
       "2    abounds\n",
       "3  abundance\n",
       "4   abundant"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-11fb3492-71ff-405e-afd1-d40caf4a94d5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-faced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abolish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11fb3492-71ff-405e-afd1-d40caf4a94d5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-11fb3492-71ff-405e-afd1-d40caf4a94d5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-11fb3492-71ff-405e-afd1-d40caf4a94d5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            0\n",
       "0     2-faced\n",
       "1     2-faces\n",
       "2    abnormal\n",
       "3     abolish\n",
       "4  abominable"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = pd.read_csv(\"positive-words.txt\", header = None)\n",
    "pos.head()\n",
    "\n",
    "neg = pd.read_csv(\"negative-words.txt\", header = None)\n",
    "neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tzsOipjbc9ED"
   },
   "outputs": [],
   "source": [
    "def compute_sentiment(gen_tokens, ref_tokens, pos, neg ):\n",
    "    result = None\n",
    "    g_positive_tokens = g_negative_tokens = []\n",
    "    r_positive_tokens = r_negative_tokens = []\n",
    "    # add your code here\n",
    "    gen_sentiment = []\n",
    "    for generated in gen_tokens:\n",
    "      g_positive_tokens = g_negative_tokens = []\n",
    "      g_positive_tokens = [token for token in generated if token in pos]\n",
    "      g_negative_tokens = [token for token in generated if token in neg]\n",
    "      # (#pos - #neg )/(#pos + #neg)\n",
    "      try :\n",
    "        generated_sentiment = (len(g_positive_tokens)- len(g_negative_tokens))/(len(g_positive_tokens)+len(g_negative_tokens))\n",
    "        gen_sentiment.append(generated_sentiment)\n",
    "      except ZeroDivisionError:\n",
    "        gen_sentiment.append(0)\n",
    "    ref_sentiment = []\n",
    "    for reference in ref_tokens:\n",
    "      r_positive_tokens = r_negative_tokens = []\n",
    "      r_positive_tokens = [token for token in reference if token in pos]\n",
    "      r_negative_tokens = [token for token in reference if token in neg]\n",
    "      # (#pos - #neg )/(#pos + #neg)\n",
    "      try :\n",
    "        reference_sentiment = (len(r_positive_tokens)- len(r_negative_tokens))/(len(r_positive_tokens)+len(r_negative_tokens))\n",
    "        ref_sentiment.append(reference_sentiment)\n",
    "      except ZeroDivisionError:\n",
    "        ref_sentiment.append(0)\n",
    "      \n",
    "    result = pd.DataFrame({'gen_sentiment':gen_sentiment, 'ref_sentiment':ref_sentiment})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GNIaZMcDc9ED",
    "outputId": "4b98a488-1167-4fce-ed10-c0c61fd50889"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7cea72b7-ee1c-4b96-a88f-ecc930266c8e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_sentiment</th>\n",
       "      <th>ref_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.777778</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cea72b7-ee1c-4b96-a88f-ecc930266c8e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7cea72b7-ee1c-4b96-a88f-ecc930266c8e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7cea72b7-ee1c-4b96-a88f-ecc930266c8e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   gen_sentiment  ref_sentiment\n",
       "0       0.000000      -0.500000\n",
       "1      -0.777778       0.076923\n",
       "2       0.666667       0.200000\n",
       "3       1.000000       0.200000\n",
       "4       0.600000      -0.333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_sentiment(gen_tokens, \n",
    "                           ref_tokens, \n",
    "                           pos[0].values,\n",
    "                           neg[0].values)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "o2AEE8ywc9ED",
    "outputId": "9b7d5324-1d1b-4e15-abcf-58adde5bbfae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-81c90227-deb3-447e-9104-d0ac5a36ae32\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_sentiment</th>\n",
       "      <th>ref_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.777778</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81c90227-deb3-447e-9104-d0ac5a36ae32')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-81c90227-deb3-447e-9104-d0ac5a36ae32 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-81c90227-deb3-447e-9104-d0ac5a36ae32');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   gen_sentiment  ref_sentiment\n",
       "0       0.000000      -0.500000\n",
       "1      -0.777778       0.076923\n",
       "2       0.666667       0.200000\n",
       "3       1.000000       0.200000\n",
       "4       0.600000      -0.333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_sentiment(gen_tokens, \n",
    "                           ref_tokens, \n",
    "                           pos[0].values,\n",
    "                           neg[0].values)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DD3d3aRc9ED"
   },
   "source": [
    "## Q3: Performance Evaluation\n",
    "\n",
    "\n",
    "Next, we evaluate how accurate the ChatGPT-generated answers are, compared to the human-generated answers. One widely used method is to calculate the `precision` and `recall` of n-grams. For simplicity, we only calculate bigrams here. You can try unigram, trigram, or n-grams in the same way.\n",
    "\n",
    "\n",
    "Define a funtion `bigram_precision_recall(gen_tokens, ref_tokens)` as follows:\n",
    "- take two parameters:\n",
    "    - `gen_tokens` is the tokenized ChatGPT-generated answers by the `tokenize` function in Q1.\n",
    "    - `ref_tokens` is the tokenized human answers by the `tokenize` function in Q1.\n",
    "- generate bigrams from each tokenized document in `gen_tokens` and `ref_tokens`.\n",
    "- for each pair of ChatGPT-generated and human answers: \n",
    "    - find the overlapping bigrams between them.\n",
    "    - compute `precision` as the number of overlapping bigrams divided by the total number of bigrams from the ChatGPT-generated answer. In other words, the bigram in the ChatGPT-generated answer is considered as a predicted value. The `precision` measures the percentage of correctly generated bigrams out of all the generated bigrams.\n",
    "    - compute `recall` as the number of overlapping bigrams divided by the total number of bigrams from the human answer. In other words, the `recall` measures the percentage of bigrams from the human answer can be successfully retrieved.\n",
    "- return the precision and recall for each pair of answers.\n",
    "\n",
    "\n",
    "Analysis: \n",
    "- Try different tokenization parameter configurations (lemmatized, remove_stopword, remove_punct), and observe how precison and recall change.\n",
    "- Which tokenization configuration can render the highest average precision and recall scores across all questions?\n",
    "- Do you think, overall, ChatGPT is able to mimic human in answering these questions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "F5VjEKu9c9EE"
   },
   "outputs": [],
   "source": [
    "def bigram_precision_recall(gen_tokens, ref_tokens):\n",
    "    \n",
    "    result = None\n",
    "    # add your code here\n",
    "    import nltk\n",
    "    ob=[]\n",
    "    for g,r in zip(gen_tokens, ref_tokens):\n",
    "      gen_bigrams = nltk.bigrams(g)\n",
    "      ref_bigrams = nltk.bigrams(r)\n",
    "      g_bigram_value = [(x,y) for (x,y) in gen_bigrams ]\n",
    "      r_bigram_value = [(x,y) for (x,y) in ref_bigrams ]\n",
    "      overlapping_bigram = [(x,y) for (x,y) in r_bigram_value if (x,y) in g_bigram_value ]\n",
    "      #the percentage of correctly generated bigrams out of all the generated bigrams\n",
    "      precision = len(overlapping_bigram)/len(g_bigram_value)\n",
    "      #measures the percentage of bigrams from the human answer can be successfully retrieved.\n",
    "      recall = len(overlapping_bigram)/len(r_bigram_value)\n",
    "      ob.append((overlapping_bigram,precision, recall))\n",
    "    result = pd.DataFrame(ob, columns =[\"overlapping\", \"precision\", \"recall\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "udGE8DqimJzg",
    "outputId": "ccd0fc60-65e2-48ae-9582-70418a24c735"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b77fc170-cd24-46e5-8d32-4026a20cc47b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overlapping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(to, pay), (it, goes)]</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(radio, stations), (can, be), (can, be), (in,...</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.026906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(a, company), (its, shareholders), (a, compan...</td>\n",
       "      <td>0.136691</td>\n",
       "      <td>0.057402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(to, be), (be, the), (the, local)]</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(., if), (,, it), (it, 's), (., as), (as, a),...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.072165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b77fc170-cd24-46e5-8d32-4026a20cc47b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b77fc170-cd24-46e5-8d32-4026a20cc47b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b77fc170-cd24-46e5-8d32-4026a20cc47b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                         overlapping  precision    recall\n",
       "0                            [(to, pay), (it, goes)]   0.016807  0.042553\n",
       "1  [(radio, stations), (can, be), (can, be), (in,...   0.057143  0.026906\n",
       "2  [(a, company), (its, shareholders), (a, compan...   0.136691  0.057402\n",
       "3                [(to, be), (be, the), (the, local)]   0.017647  0.051724\n",
       "4  [(., if), (,, it), (it, 's), (., as), (as, a),...   0.028571  0.072165"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = bigram_precision_recall(gen_tokens, ref_tokens)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Tg6IU_76c9EE",
    "outputId": "a124bb6c-0729-42ea-d3ff-cea916f3c234"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-936cab40-cdd5-4fb3-8657-3c76b648254f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overlapping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(to, pay), (it, goes)]</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(radio, stations), (can, be), (can, be), (in,...</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.026906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(a, company), (its, shareholders), (a, compan...</td>\n",
       "      <td>0.136691</td>\n",
       "      <td>0.057402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(to, be), (be, the), (the, local)]</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(., if), (,, it), (it, 's), (., as), (as, a),...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.072165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-936cab40-cdd5-4fb3-8657-3c76b648254f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-936cab40-cdd5-4fb3-8657-3c76b648254f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-936cab40-cdd5-4fb3-8657-3c76b648254f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                         overlapping  precision    recall\n",
       "0                            [(to, pay), (it, goes)]   0.016807  0.042553\n",
       "1  [(radio, stations), (can, be), (can, be), (in,...   0.057143  0.026906\n",
       "2  [(a, company), (its, shareholders), (a, compan...   0.136691  0.057402\n",
       "3                [(to, be), (be, the), (the, local)]   0.017647  0.051724\n",
       "4  [(., if), (,, it), (it, 's), (., as), (as, a),...   0.028571  0.072165"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = bigram_precision_recall(gen_tokens, \n",
    "                                 ref_tokens)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQhTyJ4pc9EE"
   },
   "source": [
    "## Q4 Compute TF-IDF\n",
    "\n",
    "Define a function `compute_tf_idf(tokenized_docs)` as follows: \n",
    "- Take paramter `tokenized_docs`, i.e., a list of tokenized documents by `tokenize` function in Q1\n",
    "- Calculate tf_idf weights as shown in lecture notes (Hint: feel free to reuse the code segment in NLP Lecture Notes (II))\n",
    "- Return the smoothed normalized `tf_idf` array, where each row stands for a document and each column denotes a word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "za06_LCjS6b0"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YmQ7kn62c9EE"
   },
   "outputs": [],
   "source": [
    "def compute_tfidf(tokenized_docs):\n",
    "    # add your code here\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import normalize\n",
    "    import nltk, re, string\n",
    "\n",
    "    smoothed_tf_idf = None\n",
    "\n",
    "    def get_doc_tokens(doc):\n",
    "        token_count={token:doc.count(token) for token in set(doc)}\n",
    "        return token_count\n",
    "    docs_tokens={idx:get_doc_tokens(doc) \\\n",
    "             for idx,doc in enumerate(tokenized_docs)} \n",
    "    dtm = pd.DataFrame.from_dict(docs_tokens,orient=\"index\")\n",
    "    dtm = dtm.fillna(0)\n",
    "    # sort by index (i.e. doc id)\n",
    "    dtm = dtm.sort_index(axis = 0)\n",
    "    # convert dtm to numpy arrays\n",
    "    tf=dtm.values\n",
    "    # sum the value of each row\n",
    "    doc_len=tf.sum(axis=1)\n",
    "    doc_len[:,None]\n",
    "    # divide dtm matrix by the doc length matrix\n",
    "    tf=np.divide(tf, doc_len[:,None])\n",
    "    # set float precision to print nicely\n",
    "    np.set_printoptions(precision=2)\n",
    "    df=np.where(tf>0,1,0)\n",
    "    smoothed_idf=np.log(np.divide(len(tokenized_docs)+1, np.sum(df, axis=0)+1))+1\n",
    "    smoothed_tf_idf=normalize(tf*smoothed_idf)\n",
    "    return smoothed_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hkvoiux2mNYY",
    "outputId": "1c64a1cf-eb02-4627-c575-54f9636c25cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.lemmatized=True, remove_stopword=False, remove_punct = True:\n",
      " Shape: (200, 1438)\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      " Shape: (200, 1272)\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      " Shape: (200, 1644)\n",
      "\n",
      "4.lemmatized=False, remove_stopword=False, remove_punct = False:\n",
      " Shape: (200, 1666)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=True, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"3.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"4.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGDe8BK4c9EE"
   },
   "source": [
    "Try different tokenization options to see how these options affect TFIDF matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUiUC92Ac9EE",
    "outputId": "33f5c026-122c-4d36-ac8c-eef1f07d2b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.lemmatized=True, remove_stopword=False, remove_punct = True:\n",
      " Shape: (200, 1438)\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      " Shape: (200, 1272)\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      " Shape: (200, 1644)\n",
      "\n",
      "4.lemmatized=False, remove_stopword=False, remove_punct = False:\n",
      " Shape: (200, 1666)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test tfidf generation using questions\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=True, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"3.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"4.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqWfv67Rc9EE"
   },
   "source": [
    "## Q5. Assess similarity. \n",
    "\n",
    "\n",
    "Define a function `assess_similarity(question_tokens, gen_tokens, ref_tokens)`  as follows: \n",
    "- Take three inputs:\n",
    "   - `question_tokens`: tokenized questions by `tokenize` function in Q1\n",
    "   - `gen_tokens`: tokenized ChatGPT-generated answers by `tokenize` function in Q1\n",
    "   - `ref_tokens`: tokenized human answers by `tokenize` function in Q1\n",
    "- Concatenate these three token lists into a single list to form a corpus\n",
    "- Calculate the smoothed normalized tf_idf matrix for the concatenated list using the `compute_tfidf` function defined in Q3.\n",
    "- Split the tf_idf matrix into sub-matrices corresponding to `question_tokens`, `gen_tokens`, and `ref_tokens` respectively\n",
    "- For each question, find its similarities to the paired ChatGPT-generated answer and human answer.\n",
    "- For each pair of ChatGPT-generated answer and human answer, find their similarity\n",
    "- Print out the following:\n",
    "    - the question which has the largest similarity to the ChatGPT-generated answer.\n",
    "    - the question which has the largest similarity to the human answer.\n",
    "    - the pair of ChatGPT-generated and human answers which have the largest similarity.\n",
    "- Return a DataFrame with the three columns for the similarities among questions and answers.\n",
    "\n",
    "\n",
    "\n",
    "Analysis: \n",
    "- Try different tokenization parameter configurations (lemmatized, remove_stopword, remove_punct), and observe how similarities change.\n",
    "- Based on similarity, do you think ChatGPT-generate answers are more (or less) relevant to questions than human answers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "g014Lv4ac9EE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def assess_similarity(question_tokens, gen_tokens, ref_tokens):\n",
    "    from sklearn.metrics import pairwise_distances\n",
    "    import numpy as np\n",
    "    result = None\n",
    "    \n",
    "    # Add your code here\n",
    "    corpus = question_tokens+gen_tokens+ref_tokens\n",
    "    smoothed_normalized_tf_idf = compute_tfidf(corpus)\n",
    "\n",
    "    question_tokens_tfidf = compute_tfidf(question_tokens)\n",
    "    gen_tokens_tfidf = compute_tfidf(gen_tokens)\n",
    "    ref_tokens_tfidf = compute_tfidf(ref_tokens)\n",
    "\n",
    "    question_token_sim = 1-pairwise_distances(question_tokens_tfidf, metric = 'cosine')\n",
    "    question_gen_sim = 1-pairwise_distances(gen_tokens_tfidf, metric = 'cosine')\n",
    "    gen_ref_sim = 1-pairwise_distances(ref_tokens_tfidf, metric = 'cosine')\n",
    "    \n",
    "    np.argsort(question_token_sim)[:,::-1][0,0:2]\n",
    "    np.argsort(question_gen_sim)[:,::-1][0,0:2]\n",
    "    np.argsort(gen_ref_sim)[:,::-1][0,0:2]\n",
    " \n",
    "\n",
    "    question_token_sim = 1-pairwise_distances(question_tokens_tfidf, metric = 'cosine')\n",
    "    question_gen_sim = 1-pairwise_distances(gen_tokens_tfidf, metric = 'cosine')\n",
    "    gen_ref_sim = 1-pairwise_distances(ref_tokens_tfidf, metric = 'cosine')\n",
    "    \n",
    "\n",
    "    result = pd.DataFrame({\"question_ref_sim\": question_token_sim,\"question_gen_sim\": question_gen_sim,\"gen_ref_sim\":gen_ref_sim})  \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Split the tf_idf matrix into sub-matrices corresponding to question_tokens, gen_tokens, and ref_tokens respectively\n",
    "    For each question, find its similarities to the paired ChatGPT-generated answer and human answer.\n",
    "    For each pair of ChatGPT-generated answer and human answer, find their similarity\n",
    "    Print out the following:\n",
    "\n",
    "    the question which has the largest similarity to the ChatGPT-generated answer.\n",
    "    the question which has the largest similarity to the human answer.\n",
    "    the pair of ChatGPT-generated and human answers which have the largest similarity.\n",
    "    Return a DataFrame with the three columns for the similarities among questions and answers.\n",
    "    \"\"\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "VHXS06XnmQWx",
    "outputId": "782e93e5-c57d-43e0-b6fe-a1c0dfa86362"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-384484789b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mref_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"human_answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_stopword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_punct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-17de9f6ed7ee>\u001b[0m in \u001b[0;36massess_similarity\u001b[0;34m(question_tokens, gen_tokens, ref_tokens)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"question_ref_sim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion_token_sim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"question_gen_sim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion_gen_sim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"gen_ref_sim\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgen_ref_sim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0mraw_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Per-column arrays must each be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# Once case is tested here. \n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "gen_tokens = tokenize(data[\"chatgpt_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "ref_tokens = tokenize(data[\"human_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "\n",
    "result = assess_similarity(question_tokens, gen_tokens, ref_tokens)\n",
    "result.head()\n",
    "\n",
    "# You need to test other cases so that you can answer the analysis questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnR8el0yc9EE"
   },
   "outputs": [],
   "source": [
    "# Once case is tested here. \n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "gen_tokens = tokenize(data[\"chatgpt_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "ref_tokens = tokenize(data[\"human_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "\n",
    "result = assess_similarity(question_tokens, gen_tokens, ref_tokens)\n",
    "result.head()\n",
    "\n",
    "# You need to test other cases so that you can answer the analysis questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvZexVPOc9EE"
   },
   "source": [
    "## Q6 (Bonus): Further Analysis (Open question)\n",
    "\n",
    "\n",
    "- Can you find at least three significant differences between ChatGPT-generated and human answeres? Use data to support your answer.\n",
    "- Based on these differences, are you able to design a classifier to identify ChatGPT generated answers? Implement your ideas using traditional machine learning models, such as SVM, decision trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoHYrbSZc9EE"
   },
   "source": [
    "## Test\n",
    "\n",
    "Please move all your unit tests into the main block to make grading easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXpjMXv0c9EE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test queston 1:\n",
    "    question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "    gen_tokens = tokenize(data[\"chatgpt_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "    ref_tokens = tokenize(data[\"human_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "    \n",
    "    # Test question 2\n",
    "    #pos = pd.read_csv(\"../Notes/NLP/positive-words.txt\", header = None)\n",
    "    #neg = pd.read_csv(\"../Notes/NLP/negative-words.txt\", header = None)\n",
    "    pos = pd.read_csv(\"positive-words.txt\", header = None)\n",
    "    neg = pd.read_csv(\"negative-words.txt\", header = None)\n",
    "\n",
    "    result = compute_sentiment(gen_tokens, \n",
    "                           ref_tokens, \n",
    "                           pos[0].values,\n",
    "                           neg[0].values)\n",
    "    print(result.head())\n",
    "    \n",
    "    # Test question 3\n",
    "    result = bigram_precision_recall(gen_tokens, \n",
    "                                 ref_tokens)\n",
    "    print(result.head())\n",
    "    \n",
    "    \n",
    "    # Test question 4\n",
    "    dtm = compute_tfidf(question_tokens)\n",
    "    print(f\"1.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "    Shape: {dtm.shape}\\n\")\n",
    "    \n",
    "    # Test question 5\n",
    "    result = assess_similarity(question_tokens, gen_tokens, ref_tokens)\n",
    "    print(result.head())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
